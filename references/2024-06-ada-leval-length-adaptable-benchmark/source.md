# Ada-LEval: Evaluating Long-Context LLMs with Length-Adaptable Benchmarks

**Authors:** Chonghua Wang, Haodong Duan, Songyang Zhang, Dahua Lin, Kai Chen
**Affiliations:** Shanghai AI Laboratory, Shanghai Jiao Tong University

## Publication Status

- **arXiv preprint:** April 2024, arXiv:2404.06480
- **Peer-reviewed:** Yes
- **Conference:** NAACL 2024 (2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1: Long Papers), pages 3712--3724, Mexico City, Mexico, June 2024
- **Status:** Published conference paper

## Preferred Citation

Cite the NAACL 2024 version:

> Wang, C., Duan, H., Zhang, S., Lin, D., & Chen, K. (2024). Ada-LEval: Evaluating Long-Context LLMs with Length-Adaptable Benchmarks. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 3712--3724.

## Links

- arXiv: https://arxiv.org/abs/2404.06480
- ACL Anthology: https://aclanthology.org/2024.naacl-long.205/
- Code: https://github.com/open-compass/Ada-LEval
