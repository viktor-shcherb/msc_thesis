# Conclusion [p. 11]

The conclusion restates the main contribution: an efficient dense model family (3B, 8B, 14B), each released as base/instruct/reasoning variants, produced through iterative pruning and distillation from larger teachers (Mistral Small 3.1 and Medium 3).

Key closing points from the paper [p. 11]:

1. Models target resource-constrained deployment settings.
2. All variants include vision support.
3. Context support reaches 256K (base/instruct).
4. Release is framed as part of Mistral's open-source commitment.

## Core contributors [p. 11]

- Alexander H. Liu
- Kartik Khandelwal
- Sandeep Subramanian
- Victor Jouault

The paper also includes a long contributors list on page 11.
