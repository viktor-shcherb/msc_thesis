# HELMET: How to Evaluate Long-Context Language Models Effectively and Thoroughly

**Authors:** Howard Yen, Tianyu Gao, Minmin Hou, Ke Ding, Daniel Fleischer, Peter Izsak, Moshe Wasserblat, Danqi Chen
**Affiliations:** Princeton University, Intel Labs

## Publication Status

- **arXiv preprint:** October 2024, arXiv:2410.02694
- **Peer-reviewed:** Yes
- **Conference:** ICLR 2025 (International Conference on Learning Representations), April 24--28, 2025, Singapore
- **Status:** Published conference paper

## Preferred Citation

Cite the ICLR 2025 version:

> Yen, H., Gao, T., Hou, M., Ding, K., Fleischer, D., Izsak, P., Wasserblat, M., & Chen, D. (2025). HELMET: How to Evaluate Long-Context Language Models Effectively and Thoroughly. In International Conference on Learning Representations (ICLR 2025).

## Links

- arXiv: https://arxiv.org/abs/2410.02694
- OpenReview: https://openreview.net/forum?id=293V3bJbmE
- Code: https://github.com/princeton-nlp/HELMET
