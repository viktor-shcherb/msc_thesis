# C Randomizing Distractor Order in Multi-Document QA [p. 14-15]

The prompt instructs the language model to use the provided search results to answer the question. There may be a prior in the pre-training or instruction fine-tuning data to treat search results as sorted by decreasing relevance (i.e., the documents near the beginning of the input context are more likely to be useful than those at the end). To validate that the conclusions are not simply a byproduct of this bias, the authors run experiments with the modified instruction "Write a high-quality answer for the given question using only the provided search results (some of which might be irrelevant). The search results are ordered randomly." In addition, they randomly shuffle the *k* - 1 distractor documents. [p. 14-15]

Figure 14 presents the results of this experiment. The U-shaped performance curve persists, with performance degrading when language models must use information in the middle of their input contexts. Comparing the results in section 2.3 with those when randomizing the distractor order and mentioning such in the prompt, randomization slightly decreases performance when the relevant information is at the very beginning of the context, and slightly increases performance when using information in the middle and end of the context. [p. 15]

**Figure 14** (p. 15): "Language model performance when randomizing the order of the distractors (rather than presenting them in order of decreasing relevance) and mentioning as such in the prompt."

The figure shows accuracy (y-axis, approximately 55-75%) vs. position of document with the answer (x-axis, 1st to 20th) for 20 total retrieved documents (~4K tokens, randomly ordered). Six models are shown: claude-1.3, claude-1.3-100k, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613, mpt-30b-instruct, and longchat-13b-16k. The U-shaped pattern persists. Compared to the default ordered setting, performance at position 1 is slightly lower and performance in the middle and end is slightly higher, but the overall trend is the same.
