# 7 Conclusion [p. 11]

The authors empirically study how language models use long input contexts via a series of controlled experiments. They show that language model performance degrades significantly when changing the position of relevant information, indicating that models struggle to robustly access and use information in long input contexts. In particular, performance is often lowest when models must use information in the middle of long input contexts. A preliminary investigation of the role of (i) model architecture, (ii) query-aware contextualization, and (iii) instruction fine-tuning is conducted to better understand how they affect how language models use context. Finally, a practical case study of open-domain question answering is presented, finding that the performance of language model readers saturates far before retriever recall. The results and analysis provide a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models. [p. 11]
