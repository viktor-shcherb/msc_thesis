# 5 Is More Context Is Always Better? A Case Study With Open-Domain QA [p. 9-10]

The results indicate that prompting language models with longer input contexts is a trade-off -- providing the language model with more information may help it perform the downstream task, but it also increases the amount of content that the model must reason over, potentially decreasing accuracy. Even if a language model can take in 16K tokens, is it actually beneficial to provide 16K tokens of context? The answer to this question is ultimately downstream task-specific since it depends on the marginal value of the added context and the model's ability to effectively use long input contexts, but a case study with open-domain question answering on NaturalQuestions-Open is performed to better understand this trade-off in existing language models. [p. 9]

Language models are used in a standard retriever-reader setup. A retrieval system (Contriever, fine-tuned on MS-MARCO) takes an input query from NaturalQuestions-Open and returns the *k* documents from Wikipedia with the highest relevance score. To condition language models on these retrieved documents, they are simply included in the prompt. Retriever recall and reader accuracy (whether any of the annotated answers appear in the predicted output) are evaluated as a function of the number of retrieved documents *k*. A subset of NaturalQuestions-Open where the long answer is a paragraph (as opposed to a table or a list) is used. [p. 9-10]

Figure 11 presents retriever recall and open-domain QA results. Reader model performance saturates long before retriever performance saturates, indicating that readers are not effectively using the extra context. Using more than 20 retrieved documents only marginally improves reader performance (approximately 1.5% for GPT-3.5-Turbo and approximately 1% for Claude-1.3), while significantly increasing the input context length (and thus latency and cost). These results, coupled with the observation that models are often better at retrieving and using information at the start or end of the input contexts, suggest that effective reranking of retrieved documents (pushing relevant information closer to the start of the input context) or ranked list truncation (retrieving fewer documents when appropriate; Arampatzis et al., 2009) may be promising directions for improving how language-model-based readers use retrieved context. [p. 10]

**Figure 11** (p. 10): "Retriever recall and model performance as a function of the number of retrieved documents. Model performance saturates long before retriever recall, indicating that the models have difficulty making use of the extra retrieved documents."

Single panel plots metric (y-axis, approximately 50-90%) vs. number of retrieved docs (x-axis, 5 to 50). Seven series are shown: claude-1.3, claude-1.3-100k, gpt-3.5-turbo-0613, gpt-3.5-turbo-16k-0613, mpt-30b-instruct, longchat-13b-16k, and contriever recall (red dashed line). Contriever recall increases steeply from approximately 70% at 5 docs to approximately 88% at 50 docs. Reader model performance curves are much flatter: GPT-3.5-Turbo and GPT-3.5-Turbo (16K) plateau around 55-57% after 20 documents. Claude-1.3 and Claude-1.3 (100K) plateau around 50-52%. MPT-30B-Instruct and LongChat-13B (16K) are lowest at approximately 45-48%. The gap between retriever recall and reader performance widens substantially as the number of documents increases.
