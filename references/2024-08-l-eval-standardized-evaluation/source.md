# L-Eval: Instituting Standardized Evaluation for Long Context Language Models

**Authors:** Chenxin An, Shansan Gong, Ming Zhong, Xingjian Zhao, Mukai Li, Jun Zhang, Lingpeng Kong, Xipeng Qiu
**Affiliations:** Fudan University, The University of Hong Kong, University of Illinois Urbana-Champaign, Shanghai AI Lab

## Publication Status

- **arXiv preprint:** July 2023, arXiv:2307.11088
- **Peer-reviewed:** Yes
- **Conference:** ACL 2024 (62nd Annual Meeting of the Association for Computational Linguistics, Volume 1: Long Papers), pages 14388--14411, August 2024, Bangkok, Thailand
- **Award:** Outstanding Paper Award
- **Status:** Published conference paper

## Preferred Citation

Cite the ACL 2024 version:

> An, C., Gong, S., Zhong, M., Zhao, X., Li, M., Zhang, J., Kong, L., & Qiu, X. (2024). L-Eval: Instituting Standardized Evaluation for Long Context Language Models. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 14388--14411.

## Links

- arXiv: https://arxiv.org/abs/2307.11088
- ACL Anthology: https://aclanthology.org/2024.acl-long.776/
- DOI: https://doi.org/10.18653/v1/2024.acl-long.776
- Code: https://github.com/OpenLMLab/LEval
