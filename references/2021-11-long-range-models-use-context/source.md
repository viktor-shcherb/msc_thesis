# Do Long-Range Language Models Actually Use Long-Range Context?

**Authors:** Simeng Sun, Kalpesh Krishna, Andrew Mattarella-Micke, Mohit Iyyer
**Affiliations:** Simeng Sun, Kalpesh Krishna, Mohit Iyyer (University of Massachusetts Amherst); Andrew Mattarella-Micke (Intuit AI)

## Publication Status

- **arXiv preprint:** September 2021, arXiv:2109.09115
- **Peer-reviewed:** Yes
- **Conference:** EMNLP 2021 (Conference on Empirical Methods in Natural Language Processing), November 7--11, 2021, Online and Punta Cana, Dominican Republic, pages 807--822
- **Status:** Published conference paper

## Preferred Citation

Cite the EMNLP 2021 version:

> Sun, S., Krishna, K., Mattarella-Micke, A., & Iyyer, M. (2021). Do Long-Range Language Models Actually Use Long-Range Context? In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 807--822.

## Links

- arXiv: https://arxiv.org/abs/2109.09115
- ACL Anthology: https://aclanthology.org/2021.emnlp-main.62/
- DOI: https://doi.org/10.18653/v1/2021.emnlp-main.62
