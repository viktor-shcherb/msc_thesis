# Quantifying Attention Flow in Transformers

**Authors:** Samira Abnar, Willem Zuidema
**Affiliation:** ILLC, University of Amsterdam

## Publication Status

- **arXiv preprint:** May 2020, arXiv:2005.00928
- **Peer-reviewed:** Yes
- **Conference:** Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL 2020), pages 4190--4197, Online, July 2020. Association for Computational Linguistics.
- **DOI:** 10.18653/v1/2020.acl-main.385
- **Status:** Published conference paper

## Preferred Citation

Cite the ACL 2020 version:

> Abnar, S. & Zuidema, W. (2020). Quantifying Attention Flow in Transformers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4190--4197, Online. Association for Computational Linguistics.

## Links

- arXiv: https://arxiv.org/abs/2005.00928
- ACL Anthology: https://aclanthology.org/2020.acl-main.385/
- Code: https://github.com/samiraabnar/attention_flow
