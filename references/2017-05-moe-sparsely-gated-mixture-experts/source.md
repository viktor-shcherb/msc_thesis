# Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer

**Authors:** Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, Jeff Dean
**Affiliations:** Google Brain, Jagiellonian University

## Publication Status

- **arXiv preprint:** January 2017, arXiv:1701.06538
- **Peer-reviewed:** Yes
- **Conference:** 5th International Conference on Learning Representations (ICLR 2017), Toulon, France, April 24--26, 2017
- **Status:** Published conference paper

## Preferred Citation

Cite the ICLR 2017 version:

> Shazeer, N., Mirhoseini, A., Maziarz, K., Davis, A., Le, Q., Hinton, G., & Dean, J. (2017). Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer. In International Conference on Learning Representations (ICLR 2017).

## Links

- arXiv: https://arxiv.org/abs/1701.06538
- OpenReview: https://openreview.net/forum?id=B1ckMDqlg
