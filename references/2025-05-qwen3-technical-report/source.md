# Qwen3 Technical Report

**Authors:** Qwen Team (An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, et al.)
**Affiliation:** Alibaba Group

## Publication Status

- **arXiv preprint:** May 2025, arXiv:2505.09388
- **Peer-reviewed:** No
- **Conference/Journal:** None
- **Status:** Preprint

Qwen3 was released as a technical report alongside model weights in sizes ranging from 0.6B to 235B parameters. The models were released under Apache 2.0 license. The report describes the full Qwen3 model family including dense language models (0.6B, 1.7B, 4B, 8B, 14B, 32B) and Mixture-of-Experts models (30B-A3B, 235B-A22B), covering architecture, training data (36T tokens), and evaluation across both thinking (reasoning) and non-thinking modes.

## Preferred Citation

> Qwen Team. (2025). Qwen3 Technical Report. arXiv:2505.09388.

## Links

- arXiv: https://arxiv.org/abs/2505.09388
- Code: https://github.com/QwenLM/Qwen3
- Models: https://huggingface.co/Qwen
- ModelScope: https://modelscope.cn/organization/qwen
