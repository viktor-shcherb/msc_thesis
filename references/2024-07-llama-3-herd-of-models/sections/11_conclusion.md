# 10 Conclusion [p. 70â€“71]

[p. 70] In many ways, the development of high-quality foundation models is still in its infancy. The experience in developing Llama 3 suggests that substantial further improvements of these models are on the horizon. Throughout the development of the Llama 3 model family, a strong focus on high-quality data, scale, and simplicity consistently yielded the best results. In preliminary experiments, more complex model architectures and training recipes were explored but the benefits of such approaches were not found to outweigh the additional complexity they introduce in model development. [p. 70]

Developing a flagship foundation model such as Llama 3 involves overcoming a plethora of deep technical problems but also requires clever organizational decisions. For example, to ensure Llama 3 is not accidentally overfitted on commonly used benchmarks, the pre-training data was procured and processed by a separate team that was strongly incentivized to prevent contamination of that pre-training data with external benchmarks. As another example, human evaluations are kept trustworthy by allowing only a small set of researchers who do not contribute to model development to perform and access these evaluations. While such organizational decisions are rarely discussed in technical papers, they were found to be pivotal to the successful development of the Llama 3 family of models. [p. 70]

The details of the development process are shared because of the belief that this will: **(1)** help the larger research community understand the key factors of foundation model development and **(2)** contribute to a more informed debate about the future of foundation models in the general public. Preliminary experiments with integrating multimodal capabilities into Llama 3 are also shared. While these models are still under active development and not yet ready for release, the hope is that sharing results early will accelerate research in this direction. [p. 70]

[p. 71] Following the positive outcomes of the detailed safety analyses presented in this paper, the Llama 3 language models are publicly released in order to accelerate the development of AI systems for a plethora of socially relevant use cases and enable the research community to scrutinize the models and identify ways to make them better and safer. The public release of foundation models is believed to play a key role in the responsible development of such models, and the hope is that the release of Llama 3 encourages the industry to embrace the open, responsible development of AGI. [p. 71]
