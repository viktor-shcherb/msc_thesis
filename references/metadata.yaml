# =============================================================================
# References Ontology — Controlled vocabularies for reference categorization
# =============================================================================
# Per-paper metadata is stored in YAML front matter of each analysis.md file.
# This file contains only the shared ontology (categories, paper types,
# relationship types, benchmarks, and models).
#
# Maintenance: see prompts/add_reference/README.md § "Ontology maintenance".
# Search:      see references/search.py or run  ./references/search.py --help
# =============================================================================

ontology:
  categories:
  - id: architecture
    description: Core Transformer architecture design and modifications
  - id: position-encoding
    description: Positional encoding methods (absolute, relative, rotary, ALiBi)
  - id: context-extension
    description: Methods for extending pretrained context windows
  - id: attention-analysis
    description: Empirical and theoretical analysis of attention patterns
  - id: benchmarking
    description: Evaluation benchmark design and methodology
  - id: long-context-evaluation
    description: Evaluation of long-context understanding capabilities
  - id: attention-efficiency
    description: Sparse, linear, and efficient attention mechanisms
  - id: mechanistic-interpretability
    description: Reverse-engineering internal model circuits and representations
  - id: in-context-learning
    description: Few-shot and zero-shot learning from context
  - id: position-bias
    description: Positional biases in model behavior and performance
  - id: model-release
    description: Open model releases and their technical reports
  - id: streaming-inference
    description: Efficient inference over unbounded input streams
  - id: pruning-and-sparsity
    description: Head pruning, weight sparsity, and model compression
  - id: probing-and-analysis
    description: Probing experiments and behavioral analysis of LLMs
  - id: reasoning-evaluation
    description: Evaluation of reasoning capabilities, including chain-of-thought
  - id: learning-theory
    description: Theoretical analysis of learning algorithms, prediction bounds, and sample complexity
  - id: scaling-laws
    description: Empirical and theoretical analysis of scaling behavior in neural language models
  - id: quantization
    description: Quantization methods and analysis of quantization effects on Transformers
  - id: graph-neural-networks
    description: Graph neural network theory, message-passing, and over-squashing
  - id: state-space-models
    description: State space models (SSMs) and structured sequence models as alternatives to attention
  paper_types:
  - conference-paper
  - journal-paper
  - preprint
  - workshop-paper
  - informal
  relationship_types:
  - id: extends
    description: This paper builds directly on the target paper's method
  - id: extended-by
    description: The target paper builds directly on this paper's method
  - id: contradicts
    description: Findings are in tension or conflict with the target paper
  - id: uses-benchmark
    description: This paper uses a benchmark introduced by the target paper
  - id: evaluates
    description: This paper evaluates a model or method from the target paper
  - id: concurrent
    description: Published around the same time addressing similar questions
  - id: complementary
    description: Addresses a related problem from a different angle
  - id: formalizes
    description: Provides formal or theoretical grounding for the target paper's findings
  benchmarks:
  - id: glue
    description: GLUE multi-task benchmark for natural language understanding
  - id: superglue
    description: SuperGLUE multi-task benchmark for natural language understanding (Wang et al., 2019)
  - id: wmt-translation
    description: WMT machine translation shared tasks
  - id: penn-treebank
    description: Penn Treebank language modeling
  - id: perplexity-1b-word
    description: 1 Billion Word Language Modeling Benchmark (Chelba et al., 2013)
  - id: perplexity-pg19
    description: Perplexity evaluation on PG-19 books corpus
  - id: perplexity-proofpile
    description: Perplexity evaluation on Proof-Pile mathematical corpus
  - id: perplexity-wikitext2
    description: Perplexity evaluation on WikiText-2 English Wikipedia corpus
  - id: perplexity-wikitext103
    description: Perplexity evaluation on WikiText-103 English Wikipedia corpus
  - id: perplexity-govreport
    description: Perplexity evaluation on GovReport long documents
  - id: perplexity-pg22
    description: Perplexity evaluation on Project Gutenberg 2019-2022 corpus
  - id: perplexity-qmsum
    description: Perplexity evaluation on QMSum meeting summarization corpus
  - id: perplexity-summscreen
    description: Perplexity evaluation on SummScreen screenplay summarization corpus
  - id: perplexity-pile
    description: Perplexity evaluation on the Pile dataset (Gao et al., 2020)
  - id: perplexity-books
    description: Perplexity evaluation on Books subset of the Pile (Gao et al., 2020)
  - id: perplexity-dclm
    description: Perplexity evaluation on DCLM-Baseline filtered Common Crawl (Li et al., 2024)
  - id: passkey-retrieval
    description: Synthetic passkey retrieval test
  - id: ruler
    description: RULER multi-task synthetic long-context benchmark
  - id: longbench
    description: LongBench bilingual multi-task long-context benchmark
  - id: longbench-v2
    description: LongBench v2 with harder human-annotated questions
  - id: longbench-pro
    description: LongBench Pro comprehensive bilingual benchmark
  - id: scrolls
    description: SCROLLS long-text understanding benchmark (fine-tuning)
  - id: zeroscrolls
    description: ZeroSCROLLS zero-shot long-text benchmark
  - id: infinitebench
    description: InfiniteBench 100K+ token evaluation
  - id: niah
    description: Needle-in-a-haystack retrieval test
  - id: babilong
    description: BABILong reasoning-in-a-haystack benchmark
  - id: lra
    description: Long Range Arena synthetic benchmark
  - id: open-llm-leaderboard
    description: HuggingFace Open LLM Leaderboard
  - id: arc
    description: AI2 Reasoning Challenge
  - id: hellaswag
    description: HellaSwag commonsense NLI
  - id: mmlu
    description: Massive Multitask Language Understanding
  - id: sst-2
    description: Stanford Sentiment Treebank binary
  - id: conll-coreference
    description: CoNLL coreference resolution
  - id: squad
    description: Stanford Question Answering Dataset
  - id: hotpotqa
    description: HotpotQA multi-hop QA
  - id: zsre
    description: Zero-Shot Relation Extraction factual editing benchmark (Levy et al., 2017; adapted by De Cao et al., 2021; Mitchell et al., 2021)
  - id: counterfact
    description: COUNTERFACT counterfactual factual-rewrite benchmark (Meng et al., 2022)
  - id: l-eval
    description: L-Eval standardized long-context evaluation
  - id: ada-leval
    description: Ada-LEval length-adaptable evaluation
  - id: drop
    description: DROP reading comprehension with discrete reasoning (Dua et al., 2019)
  - id: gsm-ic
    description: GSM-IC irrelevant context reasoning
  - id: longicl-bench
    description: LongICLBench long in-context learning benchmark
  - id: nolima
    description: NOLIMA long-context evaluation without limitations
  - id: text8
    description: text8 character-level language modeling (100M chars from Wikipedia)
  - id: enwik8
    description: enwik8 character-level language modeling (100M bytes from Wikipedia)
  - id: wikihop
    description: WikiHop multi-hop reading comprehension across documents
  - id: triviaqa
    description: TriviaQA large-scale distantly supervised QA
  - id: ontonotes-coref
    description: OntoNotes coreference resolution
  - id: imdb-sentiment
    description: IMDB movie review sentiment classification
  - id: hyperpartisan
    description: Hyperpartisan news detection (SemEval-2019 Task 4)
  - id: arxiv-summarization
    description: arXiv long document summarization
  - id: xsum
    description: XSum extreme summarization (Narayan et al., 2018)
  - id: multinews
    description: Multi-News multi-document summarization (Fabbri et al., 2019)
  - id: trec
    description: TREC question classification
  - id: mnli
    description: MultiNLI natural language inference (matched and mismatched)
  - id: cola
    description: Corpus of Linguistic Acceptability (GLUE)
  - id: mrpc
    description: Microsoft Research Paraphrase Corpus (GLUE)
  - id: natural-questions
    description: Natural Questions open-domain QA (Kwiatkowski et al., 2019)
  - id: boolq
    description: BoolQ yes/no question answering (Clark et al., 2019)
  - id: siqa
    description: SocialIQA social commonsense reasoning (Sap et al., 2019)
  - id: copa
    description: COPA Choice of Plausible Alternatives causal reasoning (Roemmele et al., 2018)
  - id: headqa
    description: HeadQA graduate-level healthcare QA (Vilares & Gomez-Rodriguez, 2019)
  - id: openbookqa
    description: OpenBookQA open book question answering (Mihaylov et al., 2018)
  - id: record
    description: ReCoRD reading comprehension with commonsense reasoning (Zhang et al., 2018)
  - id: sciq
    description: SciQ multiple-choice science QA (Welbl et al., 2017)
  - id: mqar
    description: Multi-Query Associative Recall synthetic benchmark (Arora et al., 2023)
  - id: bamboo
    description: Bamboo long-context language modeling benchmark (Dong et al., 2023)
  - id: humaneval
    description: HumanEval code generation (Chen et al., 2021)
  - id: race
    description: RACE reading comprehension from exams (Lai et al., 2017)
  - id: gsm8k
    description: GSM8K grade school math word problems (Cobbe et al., 2021)
  - id: svamp
    description: SVAMP math word problems with varying structures (Patel et al., 2021)
  - id: csqa
    description: CommonsenseQA commonsense reasoning (Talmor et al., 2019)
  - id: strategyqa
    description: StrategyQA multi-hop implicit reasoning (Geva et al., 2021)
  - id: piqa
    description: PIQA physical intuition question answering (Bisk et al., 2020)
  - id: lambada
    description: LAMBADA word prediction requiring broad discourse context (Paperno et al., 2016)
  - id: winogrande
    description: WinoGrande commonsense reasoning (Sakaguchi et al., 2021)
  - id: winograd-schema
    description: Winograd Schema Challenge coreference resolution (Levesque et al., 2012)
  - id: storycloze
    description: Story Cloze Test narrative understanding (Mostafazadeh et al., 2016)
  - id: truthfulqa
    description: TruthfulQA truthfulness and informativeness (Lin et al., 2021)
  - id: toxigen
    description: ToxiGen implicit toxic language detection (Hartvigsen et al., 2022)
  - id: bbh
    description: BIG-Bench Hard challenging reasoning tasks (Suzgun et al., 2022)
  - id: mbpp
    description: MBPP code generation benchmark (Austin et al., 2021)
  - id: agi-eval
    description: AGI Eval standardized exam benchmark (Zhong et al., 2023)
  - id: bold
    description: BOLD bias in open-ended language generation (Dhamala et al., 2021)
  - id: webqa
    description: WebQA open-domain QA on Freebase (Berant et al., 2013)
  - id: musique
    description: MuSiQue multi-hop QA via single-hop composition (Trivedi et al., 2022)
  - id: 2wikimultihopqa
    description: 2WikiMultiHopQA multi-hop QA (Ho et al., 2020)
  - id: swag
    description: SWAG adversarial commonsense inference (Zellers et al., 2018)
  - id: math-hendrycks
    description: MATH competition mathematics benchmark (Hendrycks et al., 2021)
  - id: gpqa
    description: GPQA graduate-level science QA (Rein et al., 2023)
  - id: mmlu-pro
    description: MMLU-Pro more robust multi-task language understanding (Wang et al., 2024)
  - id: ifeval
    description: IFEval instruction following evaluation
  - id: mgsm
    description: MGSM multilingual grade school math (Shi et al., 2022)
  - id: egoschema
    description: EgoSchema long-form egocentric video QA (Mangalam et al., 2023)
  - id: mrcr
    description: Multi-Round Coreference Resolution long-context diagnostic (Reid et al., 2024)
  - id: mtob
    description: Machine Translation from One Book in-context learning benchmark (Tanzer et al., 2023)
  - id: flenqa
    description: FLenQA flexible length QA reasoning benchmark (Levy et al., 2024)
  - id: rewardbench
    description: RewardBench evaluation benchmark for reward models (Lambert et al., 2024)
  - id: qm9
    description: QM9 quantum chemistry molecular property prediction (Ramakrishnan et al., 2014)
  - id: nci1
    description: NCI1 anti-lung-cancer activity classification (Wale et al., 2008)
  - id: enzymes
    description: ENZYMES 6-class enzyme classification (Borgwardt et al., 2005)
  - id: varmisuse
    description: VarMisuse program variable misuse detection (Allamanis et al., 2018)
  - id: tree-neighborsmatch
    description: Tree-NeighborsMatch synthetic over-squashing benchmark (Alon & Yahav, 2021)
  - id: imagenet-1k
    description: ImageNet-1K image classification (Deng et al., 2009)
  - id: mt-bench
    description: MT-Bench multi-turn conversation quality (Zheng et al., 2023)
  - id: arena-hard
    description: Arena-Hard automated evaluation approximating Chatbot Arena (Li et al., 2024)
  - id: livecodebench
    description: LiveCodeBench contamination-free code evaluation (Jain et al., 2024)
  - id: evalplus
    description: EvalPlus rigorous code generation evaluation (Liu et al., 2023)
  - id: multipl-e
    description: MultiPL-E polyglot code generation benchmark (Cassano et al., 2023)
  - id: needlebench
    description: NeedleBench multi-needle retrieval and reasoning (OpenCompass, 2023)
  - id: lv-eval
    description: LV-Eval balanced long-context QA benchmark (Yuan et al., 2024)
  - id: theorem-qa
    description: TheoremQA theorem-driven question answering (Chen et al., 2023)
  - id: mixeval
    description: MixEval benchmark mixture approximating Chatbot Arena (Ni et al., 2024)
  - id: alignbench
    description: AlignBench Chinese alignment evaluation (Liu et al., 2023)
  - id: c-eval
    description: C-Eval Chinese evaluation suite (Huang et al., 2023)
  - id: cmmlu
    description: CMMLU Chinese massive multitask language understanding (Li et al., 2023)
  - id: gaokao-bench
    description: Gaokao-Bench Chinese college entrance exam benchmark (Zhang et al., 2023)
  - id: alpaca-eval
    description: AlpacaEval instruction-following evaluation (Li et al., 2023)
  - id: mmmu
    description: MMMU massive multi-discipline multimodal understanding (Yue et al., 2023)
  - id: hle
    description: Humanity's Last Exam challenging reasoning benchmark (Phan et al., 2025)
  - id: aime-2025
    description: AIME 2025 American Invitational Mathematics Examination
  - id: hmmt-2025
    description: HMMT 2025 Harvard-MIT Mathematics Tournament
  - id: imo-2025
    description: IMO 2025 International Mathematical Olympiad
  - id: cmo-2025
    description: CMO 2025 China Mathematical Olympiad
  - id: ioi-2025
    description: IOI 2025 International Olympiad in Informatics
  - id: icpc-wf-2025
    description: ICPC World Finals 2025
  - id: terminal-bench
    description: Terminal Bench 2.0 code agent benchmark
  - id: browsecomp
    description: BrowseComp web browsing agent benchmark (Wei et al., 2025)
  - id: tau2-bench
    description: tau2-bench conversational agent evaluation (Barres et al., 2025)
  - id: mcp-universe
    description: MCP-Universe Model Context Protocol benchmark (Luo et al., 2025)
  - id: mcp-mark
    description: MCP-Mark Model Context Protocol evaluation (EvalSys, 2025)
  - id: tool-decathlon
    description: Tool Decathlon diverse tool-use benchmark (Li et al., 2025)
  - id: swe-verified
    description: SWE-bench Verified human-validated code benchmark (OpenAI, 2024)
  - id: swe-multilingual
    description: SWE Multilingual code benchmark (Yang et al., 2025)
  - id: imoanswerbench
    description: IMOAnswerBench mathematical reasoning benchmark (Luong et al., 2025)
  - id: 100-longbench
    description: 100-LongBench length-controllable long-context evaluation with LongScore metric (Yang et al., 2025)
  - id: helmet
    description: HELMET comprehensive long-context evaluation with controllable lengths and LLM-based metrics (Yen et al., 2024)
  - id: counting-stars
    description: Counting Stars multi-evidence position-aware long-context benchmark (Song et al., 2024)
  - id: locobench
    description: LoCoBench long-context software engineering benchmark, 8K scenarios across 10 languages at 10K-1M tokens (Qiu et al., 2025)
  - id: trec
    description: TREC question classification (Hovy et al., 2001)
  - id: banking-77
    description: Banking-77 intent classification (Casanueva et al., 2020)
  - id: clinic-150
    description: Clinic-150 intent classification and out-of-scope detection (Larson et al., 2019)
  - id: xsum
    description: XSum extreme summarization (Narayan et al., 2018)
  - id: cnn-dm
    description: CNN/DailyMail summarization (See et al., 2017)
  - id: multinews
    description: MultiNews multi-document summarization (Fabbri et al., 2019)
  - id: qasper
    description: Qasper single-document scientific QA (Dasigi et al., 2021)
  - id: asdiv
    description: ASDiv diverse math word problems (Miao et al., 2020)
  - id: mawps
    description: MAWPS math word problems (Koncel-Kedziorski et al., 2016)
  - id: carp
    description: CARP math reasoning (Zhang et al., 2023)
  - id: tabmwp
    description: TABMWP tabular math word problems (Lu et al., 2023)
  - id: collegemath
    description: CollegeMath college-level mathematics (Tang et al., 2024)
  - id: longgenbench
    description: LongGenBench long-form generation benchmark with instruction-following evaluation at 16K–32K tokens (Wu et al., 2025)
  - id: gsm-plus
    description: GSM-Plus extended grade school math with perturbations (Li et al., 2024)
  - id: bfcl
    description: Berkeley Function Calling Leaderboard tool-calling evaluation (Yan et al., 2024)
  - id: global-mmlu
    description: Global MMLU multilingual massive multitask language understanding
  - id: belebele
    description: Belebele multilingual reading comprehension benchmark (Bandarkar et al., 2023)
  - id: flores-200
    description: Flores-200 machine translation benchmark across 200 languages (NLLB Team, 2022)
  models:
  - id: transformer-base
    description: Original Transformer (Vaswani et al., 2017)
  - id: bert-base
    description: BERT base model (Devlin et al., 2019)
  - id: bert-large
    description: BERT large model (Devlin et al., 2019)
  - id: awd-lstm
    description: AWD-LSTM language model (Merity et al., 2018)
  - id: gpt-2
    description: GPT-2 (Radford et al., 2019)
  - id: gpt-2-xl
    description: GPT-2 XL 1.5B variant used in factual editing and causal tracing studies (Meng et al., 2022)
  - id: gpt-j-6b
    description: GPT-J 6B autoregressive language model (Wang and Komatsuzaki, 2021)
  - id: gpt-neox-20b
    description: GPT-NeoX 20B autoregressive language model (Black et al., 2022)
  - id: transformer-xl
    description: Transformer-XL (Dai et al., 2019)
  - id: compressive-transformer
    description: Compressive Transformer (Rae et al., 2020)
  - id: routing-transformer
    description: Routing Transformer 490M (Roy et al., 2021)
  - id: moe-sparsely-gated
    description: Sparsely-Gated MoE up to 137B parameters (Shazeer et al., 2017)
  - id: switch-transformer
    description: Switch Transformer sparse MoE up to 1.6T parameters (Fedus et al., 2022)
  - id: llama-7b
    description: LLaMA 7B (Touvron et al., 2023a)
  - id: llama-13b
    description: LLaMA 13B (Touvron et al., 2023a)
  - id: llama-33b
    description: LLaMA 33B (Touvron et al., 2023a)
  - id: llama-65b
    description: LLaMA 65B (Touvron et al., 2023a)
  - id: llama-2-long-7b
    description: Llama 2 Long 7B 32K context (Xiong et al., 2024)
  - id: llama-2-long-13b
    description: Llama 2 Long 13B 32K context (Xiong et al., 2024)
  - id: llama-2-long-34b
    description: Llama 2 Long 34B 32K context (Xiong et al., 2024)
  - id: llama-2-long-70b
    description: Llama 2 Long 70B 32K context (Xiong et al., 2024)
  - id: llama-2-7b
    description: Llama 2 7B (Touvron et al., 2023b)
  - id: llama-2-13b
    description: Llama 2 13B (Touvron et al., 2023b)
  - id: llama-2-70b
    description: Llama 2 70B (Touvron et al., 2023b)
  - id: llama-3-8b
    description: Llama 3 8B (Meta, 2024)
  - id: llama-3-70b
    description: Llama 3 70B (Meta, 2024)
  - id: llama-3.1-8b
    description: Llama 3.1 8B (Meta, 2024)
  - id: llama-3.1-70b
    description: Llama 3.1 70B (Meta, 2024)
  - id: llama-3.1-405b
    description: Llama 3.1 405B (Dubey et al., 2024)
  - id: llama-3.2-1b
    description: Llama 3.2 1B (Meta, 2024)
  - id: llama-3.2-3b
    description: Llama 3.2 3B (Meta, 2024)
  - id: qwen2-0.5b
    description: Qwen2 0.5B (Yang et al., 2024)
  - id: qwen2-1.5b
    description: Qwen2 1.5B (Yang et al., 2024)
  - id: qwen2-7b
    description: Qwen2 7B (Yang et al., 2024)
  - id: qwen2-57b-a14b
    description: Qwen2 57B-A14B MoE (Yang et al., 2024)
  - id: qwen2-72b
    description: Qwen2 72B (Yang et al., 2024)
  - id: phi-3-mini
    description: Phi-3-mini 3.8B (Abdin et al., 2024)
  - id: phi-3-medium
    description: Phi-3-medium 14B (Abdin et al., 2024)
  - id: code-llama-7b
    description: Code Llama 7B (Roziere et al., 2023)
  - id: code-llama-13b
    description: Code Llama 13B (Roziere et al., 2023)
  - id: mistral-7b
    description: Mistral 7B (Jiang et al., 2023)
  - id: mistral-7b-v0.2
    description: Mistral 7B v0.2 32K context (Mistral AI, 2024)
  - id: falcon-7b
    description: Falcon 7B (Penedo et al., 2023)
  - id: mpt-7b
    description: MPT 7B (MosaicML, 2023)
  - id: pythia-series
    description: Pythia scaling suite (Biderman et al., 2023)
  - id: mamba-130m
    description: Mamba 130M selective SSM (Gu & Dao, 2024)
  - id: mamba-370m
    description: Mamba 370M selective SSM (Gu & Dao, 2024)
  - id: mamba-790m
    description: Mamba 790M selective SSM (Gu & Dao, 2024)
  - id: mamba-1.4b
    description: Mamba 1.4B selective SSM (Gu & Dao, 2024)
  - id: mamba-2.8b
    description: Mamba 2.8B selective SSM (Gu & Dao, 2024)
  - id: smollm-360m
    description: SmolLM 360M (Allal et al., 2024)
  - id: smollm-1.7b
    description: SmolLM 1.7B (Allal et al., 2024)
  - id: gemini-1.5-pro
    description: Gemini 1.5 Pro (Reid et al., 2024)
  - id: gemini-1.5-flash
    description: Gemini 1.5 Flash (Reid et al., 2024)
  - id: gpt-4
    description: GPT-4 (OpenAI, 2023)
  - id: claude-2.1
    description: Claude 2.1 (Anthropic, 2023)
  - id: qwen-series
    description: Qwen model family (Alibaba)
  - id: qwen-1.8b
    description: Qwen 1.8B (Bai et al., 2023)
  - id: qwen-7b
    description: Qwen 7B (Bai et al., 2023)
  - id: qwen-14b
    description: Qwen 14B (Bai et al., 2023)
  - id: code-qwen-7b
    description: Code-Qwen 7B specialized for code (Bai et al., 2023)
  - id: code-qwen-14b
    description: Code-Qwen 14B specialized for code (Bai et al., 2023)
  - id: yi-6b
    description: Yi 6B (Young et al., 2024)
  - id: yi-34b
    description: Yi 34B (Young et al., 2024)
  - id: yi-9b
    description: Yi 9B depth-upscaled (Young et al., 2024)
  - id: roberta-base
    description: RoBERTa base (Liu et al., 2019)
  - id: roberta-large
    description: RoBERTa large (Liu et al., 2019)
  - id: longformer-base
    description: Longformer base (Beltagy et al., 2020)
  - id: longformer-large
    description: Longformer large (Beltagy et al., 2020)
  - id: led-large
    description: Longformer-Encoder-Decoder large (Beltagy et al., 2020)
  - id: bigbird-base
    description: BigBird base sparse attention model (Zaheer et al., 2020)
  - id: bigbird-large
    description: BigBird large sparse attention model (Zaheer et al., 2020)
  - id: bigbird-roberta
    description: BigBird-RoBERTa (Zaheer et al., 2020)
  - id: bigbird-pegasus
    description: BigBird-PEGASUS for summarization (Zaheer et al., 2020)
  - id: bigbird-etc
    description: BigBird Extended Transformer Construction (Zaheer et al., 2020)
  - id: palm-540b
    description: PaLM 540B (Chowdhery et al., 2022)
  - id: lamda-137b
    description: LaMDA 137B (Thoppilan et al., 2022)
  - id: gpt-3.5-turbo
    description: GPT-3.5-Turbo (OpenAI, 2023)
  - id: vicuna-7b-v1.5-16k
    description: Vicuna 7B v1.5 16K context (Li et al., 2023a)
  - id: tulu-2-7b
    description: Tulu 2 7B (Wang et al., 2023)
  - id: gpt-3-175b
    description: GPT-3 175B / InstructGPT text-davinci-002 (Brown et al., 2020; Ouyang et al., 2022)
  - id: gopher-280b
    description: Gopher 280B (Rae et al., 2021)
  - id: chinchilla-70b
    description: Chinchilla 70B compute-optimal model (Hoffmann et al., 2022)
  - id: chatglm2-6b
    description: ChatGLM2 6B (Du et al., 2022; Zeng et al., 2023)
  - id: chatglm2-6b-32k
    description: ChatGLM2 6B 32K context (Zeng et al., 2023)
  - id: chatglm3-6b-32k
    description: ChatGLM3 6B 32K context (THUDM, 2023)
  - id: bluelm-7b-32k
    description: BlueLM 7B 32K context (vivo AI Lab, 2023)
  - id: longchat-v1.5-7b-32k
    description: LongChat v1.5 7B 32K (Li et al., 2023)
  - id: xgen-7b-8k
    description: XGen 7B 8K (Nijkamp et al., 2023)
  - id: internlm-7b-8k
    description: InternLM 7B 8K (Team, 2023)
  - id: qwen1.5-1.8b
    description: Qwen1.5 1.8B (Alibaba, 2024)
  - id: qwen1.5-4b
    description: Qwen1.5 4B (Alibaba, 2024)
  - id: qwen1.5-7b
    description: Qwen1.5 7B (Alibaba, 2024)
  - id: qwen1.5-14b
    description: Qwen1.5 14B (Alibaba, 2024)
  - id: qwen1.5-32b
    description: Qwen1.5 32B (Alibaba, 2024)
  - id: qwen1.5-72b
    description: Qwen1.5 72B (Alibaba, 2024)
  - id: qwen1.5-110b
    description: Qwen1.5 110B (Alibaba, 2024)
  - id: qwen2.5-7b
    description: Qwen2.5 7B (Alibaba, 2024)
  - id: qwen2.5-14b
    description: Qwen2.5 14B (Alibaba, 2024)
  - id: qwen2.5-32b
    description: Qwen2.5 32B (Alibaba, 2024)
  - id: qwen2.5-72b
    description: Qwen2.5 72B (Alibaba, 2024)
  - id: gpt-4o
    description: GPT-4o (OpenAI, 2024)
  - id: claude-3.5-sonnet
    description: Claude 3.5 Sonnet (Anthropic, 2024)
  - id: gemma-2b
    description: Gemma 2B (Google DeepMind, 2024)
  - id: gemma-7b
    description: Gemma 7B (Google DeepMind, 2024)
  - id: gemma-2-2b
    description: Gemma 2 2B (Gemma Team, 2024)
  - id: gemma-2-9b
    description: Gemma 2 9B (Gemma Team, 2024)
  - id: gemma-2-27b
    description: Gemma 2 27B (Gemma Team, 2024)
  - id: gemini-2.0
    description: Gemini 2.0 (Google DeepMind, 2024)
  - id: gemini-pro
    description: Gemini Pro (Google, 2023)
  - id: mistral-medium
    description: Mistral Medium (Mistral AI, 2024)
  - id: mixtral-8x7b
    description: Mixtral 8x7B (Jiang et al., 2024)
  - id: ministral-3-3b
    description: Ministral 3 3B (Liu et al., 2026)
  - id: ministral-3-8b
    description: Ministral 3 8B (Liu et al., 2026)
  - id: ministral-3-14b
    description: Ministral 3 14B (Liu et al., 2026)
  - id: opt-125m
    description: OPT 125M (Zhang et al., 2022)
  - id: opt-350m
    description: OPT 350M (Zhang et al., 2022)
  - id: opt-1.3b
    description: OPT 1.3B (Zhang et al., 2022)
  - id: vit-s-16
    description: ViT-S/16 vision transformer (Dosovitskiy et al., 2020)
  - id: qwen3-0.6b
    description: Qwen3 0.6B (Qwen Team, 2025)
  - id: qwen3-1.7b
    description: Qwen3 1.7B (Qwen Team, 2025)
  - id: qwen3-4b
    description: Qwen3 4B (Qwen Team, 2025)
  - id: qwen3-8b
    description: Qwen3 8B (Qwen Team, 2025)
  - id: qwen3-14b
    description: Qwen3 14B (Qwen Team, 2025)
  - id: qwen3-32b
    description: Qwen3 32B (Qwen Team, 2025)
  - id: qwen3-30b-a3b
    description: Qwen3 30B-A3B MoE (Qwen Team, 2025)
  - id: qwen3-235b-a22b
    description: Qwen3 235B-A22B MoE (Qwen Team, 2025)
  - id: deepseek-7b
    description: DeepSeek 7B dense (DeepSeek-AI, 2024)
  - id: deepseek-67b
    description: DeepSeek 67B dense (DeepSeek-AI, 2024)
  - id: deepseek-moe-2b
    description: DeepSeekMoE 2B (Dai et al., 2024)
  - id: deepseek-moe-16b
    description: DeepSeekMoE 16B (Dai et al., 2024)
  - id: deepseek-moe-145b
    description: DeepSeekMoE 145B (Dai et al., 2024)
  - id: deepseek-v2
    description: DeepSeek-V2 236B MoE / 21B activated (DeepSeek-AI, 2024)
  - id: deepseek-v2-lite
    description: DeepSeek-V2-Lite 16B MoE / 2.4B activated (DeepSeek-AI, 2024)
  - id: deepseek-r1
    description: DeepSeek-R1 (Guo et al., 2025)
  - id: deepseek-v3
    description: DeepSeek-V3 MoE (Liu et al., 2024)
  - id: llama-4-maverick
    description: Llama 4 Maverick MoE (Meta, 2025)
  - id: llama-4-scout
    description: Llama 4 Scout MoE (Meta, 2025)
  - id: gemini-2.5-pro
    description: Gemini 2.5 Pro (Google DeepMind, 2025)
  - id: gemini-2.5-flash
    description: Gemini 2.5 Flash (Google DeepMind, 2025)
  - id: qwq-32b
    description: QwQ-32B reasoning model (Qwen Team, 2024)
  - id: gemma-3-1b
    description: Gemma 3 1B (Gemma Team, 2025)
  - id: gemma-3-4b
    description: Gemma 3 4B (Gemma Team, 2025)
  - id: gemma-3-12b
    description: Gemma 3 12B (Gemma Team, 2025)
  - id: gemma-3-27b
    description: Gemma 3 27B (Gemma Team, 2025)
  - id: kimi-vl-a3b
    description: Kimi-VL-A3B MoE VLM 2.8B activated / 16B total (Kimi Team, 2025)
  - id: deepseek-vl2
    description: DeepSeek-VL2 MoE VLM (Wu et al., 2024)
  - id: qwen2.5-vl-7b
    description: Qwen2.5-VL 7B dense VLM (Bai et al., 2025)
  - id: kimi-linear-48b-a3b
    description: Kimi Linear 48B-A3B MoE hybrid linear attention (Kimi Team, 2025)
  - id: kimi-k1.5
    description: Kimi k1.5 multimodal reasoning model with 128k RL context (Kimi Team, 2025)
  - id: kimi-k2-base
    description: Kimi K2 Base 1.04T total / 32B activated MoE (Kimi Team, 2025)
  - id: kimi-k2-instruct
    description: Kimi K2 Instruct 1.04T total / 32B activated MoE (Kimi Team, 2025)
  - id: kimi-k2-thinking
    description: Kimi K2 Thinking reasoning model (MoonShot, 2025)
  - id: deepseek-v3.2
    description: DeepSeek-V3.2 MoE with DeepSeek Sparse Attention (DeepSeek-AI, 2025)
  - id: deepseek-v3.2-speciale
    description: DeepSeek-V3.2-Speciale high-compute reasoning variant (DeepSeek-AI, 2025)
  - id: gpt-5
    description: GPT-5 (OpenAI, 2025)
  - id: gemini-3.0-pro
    description: Gemini 3.0 Pro (Google DeepMind, 2025)
  - id: claude-4.5-sonnet
    description: Claude 4.5 Sonnet (Anthropic, 2025)
  - id: minimax-m2
    description: MiniMax M2 (MiniMax, 2025)
  - id: moonshot-v1-128k
    description: Moonshot-v1 128K context (Moonshot AI, 2024)
  - id: llama3-8b-1m
    description: Llama 3 8B 1M context extended by Gradient (gradient.ai, 2024)
  - id: rwkv-169m
    description: RWKV 169M linear RNN (Peng et al., 2023)
  - id: rwkv-430m
    description: RWKV 430M linear RNN (Peng et al., 2023)
  - id: rwkv-1.5b
    description: RWKV 1.5B linear RNN (Peng et al., 2023)
  - id: rwkv-3b
    description: RWKV 3B linear RNN (Peng et al., 2023)
  - id: rwkv-7b
    description: RWKV 7B linear RNN (Peng et al., 2023)
  - id: rwkv-14b
    description: RWKV 14B linear RNN (Peng et al., 2023)
  - id: bloom-series
    description: BLOOM multilingual Transformer family (Scao et al., 2022)
  - id: eagle-0.4b
    description: Eagle (RWKV-5) 0.46B (Peng et al., 2024)
  - id: eagle-1.5b
    description: Eagle (RWKV-5) 1.5B (Peng et al., 2024)
  - id: eagle-3b
    description: Eagle (RWKV-5) 2.8B (Peng et al., 2024)
  - id: eagle-7b
    description: Eagle (RWKV-5) 7.5B (Peng et al., 2024)
  - id: finch-1.6b
    description: Finch (RWKV-6) 1.6B (Peng et al., 2024)
  - id: finch-3b
    description: Finch (RWKV-6) 3.1B (Peng et al., 2024)
  - id: s4
    description: S4 Structured State Space model (Gu et al., 2022)
  - id: h3
    description: H3 (Hungry Hungry Hippos) SSM-based language model (Dao et al., 2022)
  - id: hyena
    description: Hyena long convolution model (Poli et al., 2023)
  - id: linear-transformer
    description: Linear Transformer with kernel-based attention (Katharopoulos et al., 2020)
  - id: retnet-1.3b
    description: RetNet 1.3B with retention mechanism (Sun et al., 2023)
  - id: retnet-2.7b
    description: RetNet 2.7B with retention mechanism (Sun et al., 2023)
  - id: retnet-6.7b
    description: RetNet 6.7B with retention mechanism (Sun et al., 2023)
  - id: gated-deltanet-1.3b
    description: Gated DeltaNet 1.3B linear recurrent model (Yang et al., 2025)
  - id: gated-deltanet-h1-1.3b
    description: Gated DeltaNet-H1 1.3B hybrid with SWA (Yang et al., 2025)
  - id: gated-deltanet-h2-1.3b
    description: Gated DeltaNet-H2 1.3B hybrid with Mamba2 + SWA (Yang et al., 2025)
  - id: diff-transformer-3b
    description: Diff Transformer 3B with differential attention (Ye et al., 2025)
  - id: gpt-4o-mini
    description: GPT-4o-mini cost-efficient 128K context model (OpenAI, 2024)
  - id: film-7b
    description: FILM-7B 128K context creative and technical generation model (An et al., 2024)
  - id: longwriter-llama3.1-8b
    description: LongWriter-Llama3.1-8B optimized for 10K+ word generation (Bai et al., 2024)
  - id: phi-3-mini-3.8b
    description: Phi-3-mini 3.8B 128K context model (Microsoft, 2024)
  - id: phi-3.5-moe
    description: Phi-3.5-MoE 8x7B 128K context mixture-of-experts (Microsoft, 2024)
  - id: palm-2-s
    description: PaLM 2-S* (Codey) base model (Anil et al., 2023)
  - id: smollm3-3b
    description: SmolLM3 3B dual-mode reasoning model with 128K context (Bakouch et al., 2025)
  - id: qwen2.5-3b
    description: Qwen2.5 3B (Alibaba, 2024)
