# Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence

**Authors:** Bo Peng, Daniel Goldstein, Quentin Anthony, Alon Albalak, Eric Alcaide, Stella Biderman, Eugene Cheah, Xingjian Du, Teddy Ferdinan, Haowen Hou, Przemyslaw Kazienko, Kranthi Kiran GV, Jan Kocon, Bartlomiej Koptyra, Satyapriya Krishna, Ronald McClelland Jr., Jiaju Lin, Niklas Muennighoff, Fares Obeid, Atsushi Saito, Guangyu Song, Haoqin Tu, Cahya Wirawan, Stanislaw Wozniak, Ruichong Zhang, Bingchen Zhao, Qihang Zhao, Peng Zhou, Jian Zhu, Rui-Jie Zhu
**Affiliations:** RWKV Project (Linux Foundation AI & Data), EleutherAI, Recursal AI, Ohio State University, University of California Santa Barbara, SynthLabs, Charm Therapeutics, Dalle Molle Institute for Artificial Intelligence Research, Wroclaw Tech, Guangdong Laboratory of Artificial Intelligence and Digital Economy, New York University, Harvard University, Ronsor Labs, Contextual AI, Nextremer Co. Ltd., University of Chinese Academy of Sciences, University of California Santa Cruz, AI-Research.id, Tsinghua University, University of Edinburgh, LuxiTech Co. Ltd., University of British Columbia, Zyphra, Pennsylvania State University, Tano Labs

## Publication Status

- **arXiv preprint:** April 2024, arXiv:2404.05892
- **Peer-reviewed:** Yes
- **Conference/Journal:** Conference on Language Modeling (COLM), October 7--9, 2024, Philadelphia
- **Status:** Published conference paper

## Preferred Citation

Cite the COLM 2024 version:

> Peng, B., Goldstein, D., Anthony, Q., Albalak, A., Alcaide, E., Biderman, S., ... & Zhu, R.-J. (2024). Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence. In Conference on Language Modeling (COLM 2024).

## Notes

Eagle (RWKV-5) and Finch (RWKV-6) are the fifth and sixth generations of the RWKV architecture, a linear-time RNN designed to match Transformer quality while maintaining O(1) per-token inference cost. The RWKV-6 (Finch) architecture was deployed in Microsoft's Windows Copilot runtime. All models are released under Apache 2.0 license.

## Links

- arXiv: https://arxiv.org/abs/2404.05892
- Models: https://huggingface.co/RWKV
- Training code: https://github.com/RWKV/RWKV-LM
- Inference code: https://github.com/RWKV/ChatRWKV
