# Acknowledgments [p. 9]

[p. 9] Thanks to Carina Kauf and Greta Tuckute, Evelina Fedorenko and Roger Levy for valuable discussions. The authors acknowledge the MIT SuperCloud and Lincoln Laboratory Supercomputing Center for providing HPC resources that contributed to the results reported within this paper.

# Impact Statement [p. 9]

[p. 9] Across initial exploration, evaluation conditions and training runs, experiments in this paper required roughly 100 training runs on the WikiText-103 dataset. As discussed in Section 2, model size and batched evaluation were both used to minimize the energy demands of these experiments; experiments themselves were performed at the Massachusetts Green HPC center, a carbon-neutral supercomputing facility. Ultimately, results in Section 3 provide guidance toward the design of models that use context more efficiently and motivate the large-scale empirical study conducted here.
