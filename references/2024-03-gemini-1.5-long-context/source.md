# Gemini 1.5: Unlocking Multimodal Understanding Across Millions of Tokens of Context

**Authors:** Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, Timothy Lillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat, Julian Schrittwieser, Ioannis Antonoglou, Rohan Anil, Sebastian Borgeaud, Andrew Dai, Katie Millican, Ethan Dyer, Mia Glaese, Thibault Sottiaux, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, et al. (Gemini Team, Google)
**Affiliation:** Google DeepMind

## Publication Status

- **arXiv preprint:** March 2024, arXiv:2403.05530
- **Peer-reviewed:** No
- **Status:** Preprint (Google technical report)

## Preferred Citation

Cite the arXiv preprint:

> Reid, M., Savinov, N., Teplyashin, D., Lepikhin, D., Lillicrap, T., Alayrac, J., Soricut, R., Lazaridou, A., Firat, O., Schrittwieser, J., et al. (2024). Gemini 1.5: Unlocking Multimodal Understanding Across Millions of Tokens of Context. arXiv:2403.05530.

## Notes

- The author list includes over 1,000 contributors from Google DeepMind.
- Five arXiv revisions between March and December 2024 (v1--v5).
- Describes both Gemini 1.5 Pro and Gemini 1.5 Flash models.

## Links

- arXiv: https://arxiv.org/abs/2403.05530
- Blog: https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/
