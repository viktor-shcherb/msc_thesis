# In-context Learning and Induction Heads

**Authors:** Catherine Olsson, Nelson Elhage, Neel Nanda, Nicholas Joseph, Nova DasSarma, Tom Henighan, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, Chris Olah
**Affiliation:** Anthropic

## Publication Status

- **Transformer Circuits Thread:** March 2022
- **arXiv preprint:** September 2022, arXiv:2209.11895
- **Peer-reviewed:** No
- **Status:** Preprint

## Notes

This paper was originally published as part of the Transformer Circuits Thread, Anthropic's ongoing research series on mechanistic interpretability of transformer models. It remains an influential and highly-cited preprint without formal peer review.

## Preferred Citation

Cite the arXiv version:

> Olsson, C., Elhage, N., Nanda, N., Joseph, N., DasSarma, N., Henighan, T., Mann, B., Askell, A., Bai, Y., Chen, A., Conerly, T., Drain, D., Ganguli, D., Hatfield-Dodds, Z., Hernandez, D., Johnston, S., Jones, A., Kernion, J., Lovitt, L., Ndousse, K., Amodei, D., Brown, T., Clark, J., Kaplan, J., McCandlish, S., & Olah, C. (2022). In-context Learning and Induction Heads. arXiv:2209.11895.

## Links

- arXiv: https://arxiv.org/abs/2209.11895
- Transformer Circuits Thread: https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html
