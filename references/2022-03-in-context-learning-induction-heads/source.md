# In-context Learning and Induction Heads

**Authors:** Catherine Olsson\*, Nelson Elhage\*, Neel Nanda\*, Nicholas Joseph&dagger;, Nova DasSarma&dagger;, Tom Henighan&dagger;, Ben Mann&dagger;, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Scott Johnston, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, Chris Olah&Dagger;
**Affiliation:** Anthropic

\* Core Research Contributor; &dagger; Core Infrastructure Contributor; &Dagger; Correspondence to colah@anthropic.com

## Publication Status

- **Transformer Circuits Thread:** March 8, 2022
- **arXiv preprint:** September 2022, arXiv:2209.11895
- **Peer-reviewed:** No
- **Status:** Preprint

## Notes

This paper was originally published as part of the Transformer Circuits Thread, Anthropic's ongoing research series on mechanistic interpretability of transformer models. The arXiv preprint (September 2022) followed the initial Transformer Circuits publication (March 2022). The paper has not been published at a peer-reviewed venue.

## Preferred Citation

Cite the arXiv version:

> Olsson, C., Elhage, N., Nanda, N., Joseph, N., DasSarma, N., Henighan, T., Mann, B., Askell, A., Bai, Y., Chen, A., Conerly, T., Drain, D., Ganguli, D., Hatfield-Dodds, Z., Hernandez, D., Johnston, S., Jones, A., Kernion, J., Lovitt, L., Ndousse, K., Amodei, D., Brown, T., Clark, J., Kaplan, J., McCandlish, S., & Olah, C. (2022). In-context Learning and Induction Heads. arXiv:2209.11895.

## Links

- arXiv: https://arxiv.org/abs/2209.11895
- Transformer Circuits Thread: https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html
- Blog post: https://www.anthropic.com/news/in-context-learning-and-induction-heads
