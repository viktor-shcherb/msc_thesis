# References

Only references actually cited in the section notes are included below.

---

**Austin et al., 2021**
Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., and Sutton, C. Program synthesis with large language models. *arXiv preprint arXiv:2108.07732*, 2021.
Cited in 02_related-work.md and 04_investigated-solutions.md as a prior work on generating programs for reasoning.

**Brown et al., 2020**
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. *NeurIPS*, 2020.
Cited in 01_introduction.md and 02_related-work.md as foundational work on few-shot prompting with large language models.

**Chaves & Richter, 2021**
Chaves, R. P. and Richter, S. N. Look at that! BERT can be easily distracted from paying attention to morphosyntax. In *Proceedings of the Society for Computation in Linguistics 2021*, pp. 28–38, Online, February 2021. Association for Computational Linguistics.
Cited in 02_related-work.md as showing similar distractibility issues for syntactic generalization.

**Chen et al., 2022**
Chen, W., Ma, X., Wang, X., and Cohen, W. W. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. *arXiv preprint arXiv:2211.12588*, 2022.
Cited in 02_related-work.md and 04_investigated-solutions.md as prior work on solving problems with code.

**Chowdhery et al., 2022**
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. PaLM: Scaling language modeling with pathways. *arXiv preprint arXiv:2204.02311*, 2022.
Cited in 01_introduction.md, 02_related-work.md, and 04_investigated-solutions.md as the PaLM model and PROGRAM prompting source.

**Chung et al., 2022**
Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. *arXiv preprint arXiv:2210.11416*, 2022.
Cited in 01_introduction.md as part of the instruction tuning line of work.

**Clark et al., 2021**
Clark, P., Tafjord, O., and Richardson, K. Transformers as soft reasoners over language. In *Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence*, pp. 3882–3890, 2021.
Cited in 02_related-work.md as a logical reasoning benchmark containing irrelevant content.

**Cobbe et al., 2021**
Cobbe, K., Kosaraju, V., Bavarian, M., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. Training verifiers to solve math word problems. *arXiv preprint arXiv:2110.14168*, 2021.
Cited in 01_introduction.md, 02_related-work.md, 03_gsm-ic-dataset.md, and 05_experiments.md as the source of the GSM8K dataset.

**Creswell et al., 2022**
Creswell, A., Shanahan, M., and Higgins, I. Selection-inference: Exploiting large models for interpretable logical reasoning. *arXiv preprint arXiv:2205.09712*, 2022.
Cited in 02_related-work.md as work on logical reasoning where prompting alone underperforms finetuned models.

**Dohan et al., 2022**
Dohan, D., Xu, W., Lewkowycz, A., Austin, J., Bieber, D., Lopes, R. G., Wu, Y., Michalewski, H., Saurous, R. A., Sohl-Dickstein, J., Murphy, K., and Sutton, C. Language model cascades. *arXiv preprint arXiv:2207.10342*, 2022.
Cited in 02_related-work.md as work on problem decomposition prompting.

**Drozdov et al., 2022**
Drozdov, A., Schärli, N., Akyürek, E., Scales, N., Song, X., Chen, X., Bousquet, O., and Zhou, D. Compositional semantic parsing with large language models. *arXiv preprint arXiv:2209.15003*, 2022.
Cited in 02_related-work.md as work on problem decomposition and ensemble prompting.

**Dua et al., 2019**
Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S., and Gardner, M. DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In *Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, 2019.
Cited in 05_experiments.md as the DROP dataset used for extension experiments in Section 5.5.

**Gao et al., 2022**
Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., and Neubig, G. PAL: Program-aided language models. *arXiv preprint arXiv:2211.10435*, 2022.
Cited in 02_related-work.md and 04_investigated-solutions.md as prior work on solving problems with code (PAL).

**Han et al., 2022**
Han, S., Schoelkopf, H., Zhao, Y., Qi, Z., Riddell, M., Benson, L., Sun, L., Zubova, E., Qiao, Y., Burtell, M., et al. Folio: Natural language reasoning with first-order logic. *arXiv preprint arXiv:2209.00840*, 2022.
Cited in 02_related-work.md as a logical reasoning benchmark with irrelevant content.

**Hoyer et al., 1979**
Hoyer, W. J., Rebok, G. W., and Sved, S. M. Effects of varying irrelevant information on adult age differences in problem solving. *Journal of Gerontology*, 34(4):553–560, 1979.
Cited in 01_introduction.md as psychology evidence that irrelevant information decreases problem-solving accuracy.

**Jia & Liang, 2017**
Jia, R. and Liang, P. Adversarial examples for evaluating reading comprehension systems. *arXiv preprint arXiv:1707.07328*, 2017.
Cited in 02_related-work.md as showing neural QA systems are affected by adversarial distracting sentences.

**Jones & Steinhardt, 2022**
Jones, E. and Steinhardt, J. Capturing failures of large language models via human cognitive biases. *arXiv preprint arXiv:2202.12299*, 2022.
Cited in 02_related-work.md as showing distractibility issues for code generation.

**Kassner & Schütze, 2020**
Kassner, N. and Schütze, H. Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly. In *Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics*, pp. 7811–7818, Online, July 2020.
Cited in 02_related-work.md as showing distractibility in factual reasoning.

**Khashabi et al., 2017**
Khashabi, D., Khot, T., Sabharwal, A., and Roth, D. Learning what is essential in questions. In *Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)*, pp. 80–89, Vancouver, Canada, August 2017.
Cited in 02_related-work.md as follow-up work proposing learning strategies to mitigate adversarial distractors.

**Khot et al., 2022**
Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P., and Sabharwal, A. Decomposed prompting: A modular approach for solving complex tasks. *arXiv preprint arXiv:2210.02406*, 2022.
Cited in 02_related-work.md as work on problem decomposition prompting.

**Kim et al., 2022**
Kim, J., Kim, H. J., Cho, H., Jo, H., Lee, S.-W., Lee, S.-g., Yoo, K. M., and Kim, T. Ground-truth labels matter: A deeper look into input-label demonstrations. *arXiv preprint arXiv:2205.12685*, 2022.
Cited in 02_related-work.md as studying model performance with incorrect prompting exemplars.

**Kojima et al., 2022**
Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large language models are zero-shot reasoners. *arXiv preprint arXiv:2205.11916*, 2022.
Cited in 01_introduction.md, 02_related-work.md, and 04_investigated-solutions.md as the source of zero-shot chain-of-thought (0-CoT) prompting.

**Kumar et al., 2021**
Kumar, V., Maheshwary, R., and Pudi, V. Adversarial examples for evaluating math word problem solvers. In *Findings of the Association for Computational Linguistics: EMNLP 2021*, pp. 2705–2712, 2021.
Cited in 01_introduction.md and 02_related-work.md as prior work constructing arithmetic reasoning benchmarks through problem rewriting.

**Li et al., 2022**
Li, D., Rawat, A. S., Zaheer, M., Wang, X., Lukasik, M., Veit, A., Yu, F., and Kumar, S. Large language models with controllable working memory. *arXiv preprint arXiv:2211.05110*, 2022.
Cited in 02_related-work.md and 05_experiments.md as proposing knowledge-aware finetuning and showing that training with different problem types improves model robustness.

**Liang et al., 2022**
Liang, P., Bommasani, R., Lee, T., Tsipras, D., Soylu, D., Yasunaga, M., Zhang, Y., Narayanan, D., Wu, Y., Kumar, A., et al. Holistic evaluation of language models. *arXiv preprint arXiv:2211.09110*, 2022.
Cited in 02_related-work.md as evaluating various LLMs under robustness metrics including input perturbations.

**Ling et al., 2017**
Ling, W., Yogatama, D., Dyer, C., and Blunsom, P. Program induction by rationale generation: Learning to solve and explain algebraic word problems. In *Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pp. 158–167, Vancouver, Canada, July 2017.
Cited in 02_related-work.md as early work on generating intermediate steps for reasoning.

**Madaan & Yazdanbakhsh, 2022**
Madaan, A. and Yazdanbakhsh, A. Text and patterns: For effective chain of thought, it takes two to tango. *arXiv preprint arXiv:2209.07686*, 2022.
Cited in 02_related-work.md as studying model sensitivity to wrong reasoning steps in prompts.

**Marzocchi et al., 2002**
Marzocchi, G. M., Lucangeli, D., De Meo, T., Fini, F., and Cornoldi, C. The disturbing effect of irrelevant information on arithmetic problem solving in inattentive children. *Developmental Neuropsychology*, 21(1):73–92, 2002.
Cited in 01_introduction.md as psychology evidence on the effect of irrelevant information on problem solving.

**Min et al., 2022**
Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., and Zettlemoyer, L. Rethinking the role of demonstrations: What makes in-context learning work? *arXiv preprint arXiv:2202.12837*, 2022.
Cited in 02_related-work.md as studying model performance with incorrect prompting exemplars.

**Misra et al., 2023**
Misra, K., Rayz, J., and Ettinger, A. COMPS: Conceptual minimal pair sentences for testing robust property knowledge and its inheritance in pre-trained language models. In *Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics*, 2023.
Cited in 02_related-work.md as showing distractibility in factual reasoning.

**Morris et al., 2020**
Morris, J. X., Lifland, E., Yoo, J. Y., Grigsby, J., Jin, D., and Qi, Y. Textattack: A framework for adversarial attacks, data augmentation, and adversarial training in NLP. *arXiv preprint arXiv:2005.05909*, 2020.
Cited in 02_related-work.md as prior work on adversarial example generation.

**Ni et al., 2019**
Ni, J., Zhu, C., Chen, W., and McAuley, J. Learning to attend on essential terms: An enhanced retriever-reader model for open-domain question answering. In *Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, pp. 335–344, Minneapolis, Minnesota, June 2019.
Cited in 02_related-work.md as follow-up work proposing learning strategies to mitigate adversarial distractors.

**Nye et al., 2021**
Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., Sutton, C., and Odena, A. Show your work: Scratchpads for intermediate computation with language models. *arXiv preprint arXiv:2112.00114*, 2021.
Cited in 02_related-work.md as work on generating intermediate steps for reasoning.

**Ouyang et al., 2022**
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et al. Training language models to follow instructions with human feedback. *arXiv preprint arXiv:2203.02155*, 2022.
Cited in 01_introduction.md, 04_investigated-solutions.md, and 05_experiments.md as the RLHF training method behind `text-davinci-003`.

**Pandia & Ettinger, 2021**
Pandia, L. and Ettinger, A. Sorting through the noise: Testing robustness of information processing in pre-trained language models. In *Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing*, pp. 1583–1596, Online and Punta Cana, Dominican Republic, 2021.
Cited in 02_related-work.md as showing distractibility in factual reasoning.

**Pasolunghi et al., 1999**
Pasolunghi, M. C., Cornoldi, C., and De Liberto, S. Working memory and intrusions of irrelevant information in a group of specific poor problem solvers. *Memory & Cognition*, 27:779–790, 1999.
Cited in 01_introduction.md as psychology evidence on the effect of irrelevant information on problem solving.

**Patel et al., 2021**
Patel, A., Bhattamishra, S., and Goyal, N. Are NLP models really able to solve simple math word problems? *NAACL-HLT*, 2021.
Cited in 01_introduction.md, 02_related-work.md, and 05_experiments.md as the SVAMP arithmetic reasoning benchmark and prior work on constructing arithmetic reasoning benchmarks.

**Press et al., 2022**
Press, O., Zhang, M., Min, S., Schmidt, L., Smith, N. A., and Lewis, M. Measuring and narrowing the compositionality gap in language models. *arXiv preprint arXiv:2210.03350*, 2022.
Cited in 02_related-work.md as work on problem decomposition prompting.

**Raffel et al., 2020**
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring the limits of transfer learning with a unified text-to-text transformer. *Journal of Machine Learning Research*, 2020.
Cited in 02_related-work.md as the T5 model used by Li et al. (2022).

**Shi et al., 2022a**
Shi, F., Suzgun, M., Freitag, M., Wang, X., Srivats, S., Vosoughi, S., Chung, H. W., Tay, Y., Ruder, S., Zhou, D., Das, D., and Wei, J. Language models are multilingual chain-of-thought reasoners. *arXiv preprint arXiv:2210.03057*, 2022.
Cited in 02_related-work.md, 04_investigated-solutions.md, and 05_experiments.md as work on marginalizing intermediate reasoning steps (self-consistency variant).

**Zhou et al., 2022**
Zhou, D., Schärli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Bousquet, O., Le, Q., and Chi, E. Least-to-most prompting enables complex reasoning in large language models. *arXiv preprint arXiv:2205.10625*, 2022.
Cited in 01_introduction.md, 02_related-work.md, 04_investigated-solutions.md, and 05_experiments.md as the source of least-to-most prompting (LtM).

**Wang et al., 2022c**
Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Self-consistency improves chain of thought reasoning in language models. *arXiv preprint arXiv:2203.11171*, 2022c.
Cited in 01_introduction.md, 02_related-work.md, 04_investigated-solutions.md, 05_experiments.md, and 06_conclusion-discussion.md as the source of self-consistency (SC) decoding.

**Wei et al., 2022**
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou, D. Chain of thought prompting elicits reasoning in large language models. In *NeurIPS*, 2022.
Cited in 01_introduction.md, 02_related-work.md, and 04_investigated-solutions.md as the source of chain-of-thought (CoT) prompting.

**Suzgun et al., 2022**
Suzgun, M., Scales, N., Schärli, N., Gehrmann, S., Tay, Y., Chung, H. W., Chowdhery, A., Le, Q. V., Chi, E. H., Zhou, D., and Wei, J. Challenging big-bench tasks and whether chain-of-thought can solve them. *arXiv preprint arXiv:2210.09261*, 2022.
Cited in 01_introduction.md, 02_related-work.md, and 04_investigated-solutions.md as work using task descriptions before exemplars.

**Sanh et al., 2021**
Sanh, V., Webson, A., Raffel, C., Bach, S. H., Sutawika, L., Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T. L., Raja, A., et al. Multitask prompted training enables zero-shot task generalization. *arXiv preprint arXiv:2110.08207*, 2021.
Cited in 01_introduction.md and 04_investigated-solutions.md as part of the instruction tuning line of work.

**Wei et al., 2021**
Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V. Finetuned language models are zero-shot learners. *arXiv preprint arXiv:2109.01652*, 2021.
Cited in 01_introduction.md as part of the instruction tuning line of work.

**Shi et al., 2022b**
Shi, F., Fried, D., Ghazvininejad, M., Zettlemoyer, L., and Wang, S. I. Natural language to code translation with execution. In *EMNLP*, 2022.
Cited in 02_related-work.md as work on generating intermediate steps.

**Wang et al., 2022b**
Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Rationale-augmented ensembles in language models. *arXiv preprint arXiv:2207.00747*, 2022b.
Cited in 02_related-work.md as work on ensemble prompting.

**Wang et al., 2022a**
Wang, B., Min, S., Deng, X., Shen, J., Wu, Y., Zettlemoyer, L., and Sun, H. Towards understanding chain-of-thought prompting: An empirical study of what matters. *arXiv preprint arXiv:2212.10001*, 2022a.
Cited in 02_related-work.md as studying model sensitivity to wrong reasoning steps.

**Wang et al., 2021**
Wang, B., Xu, C., Wang, S., Gan, Z., Cheng, Y., Gao, J., Awadallah, A. H., and Li, B. Adversarial glue: A multi-task benchmark for robustness evaluation of language models. *arXiv preprint arXiv:2111.02840*, 2021.
Cited in 02_related-work.md as adversarial example generation work.

**Ravichander et al., 2022**
Ravichander, A., Gardner, M., and Marasovic, A. Condaqa: A contrastive reading comprehension dataset for reasoning about negation. *arXiv preprint arXiv:2211.00295*, 2022.
Cited in 02_related-work.md as model-agnostic input transformations.

**Shi et al., 2018**
Shi, H., Mao, J., Xiao, T., Jiang, Y., and Sun, J. Learning visually-grounded semantics from contrastive adversarial samples. In *Proceedings of the 27th International Conference on Computational Linguistics*, pp. 3715–3727, 2018.
Cited in 02_related-work.md as adversarial example generation work.

**Weston et al., 2015**
Weston, J., Bordes, A., Chopra, S., Rush, A. M., Van Merriënboer, B., Joulin, A., and Mikolov, T. Towards ai-complete question answering: A set of prerequisite toy tasks. *arXiv preprint arXiv:1502.05698*, 2015.
Cited in 02_related-work.md as a logical reasoning benchmark with irrelevant content.

**Sinha et al., 2019**
Sinha, K., Sodhani, S., Dong, J., Pineau, J., and Hamilton, W. L. CLUTRR: A diagnostic benchmark for inductive reasoning from text. In *Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)*, pp. 4506–4515, Hong Kong, China, 2019.
Cited in 02_related-work.md as a logical reasoning benchmark with irrelevant content.

**Tafjord et al., 2020**
Tafjord, O., Mishra, B. D., and Clark, P. Proofwriter: Generating implications, proofs, and abductive statements over natural language. *arXiv preprint arXiv:2012.13048*, 2020.
Cited in 02_related-work.md as a logical reasoning benchmark with irrelevant content.

**Webson & Pavlick, 2021**
Webson, A. and Pavlick, E. Do prompt-based models really understand the meaning of their prompts? *arXiv preprint arXiv:2109.01247*, 2021.
Cited in 02_related-work.md as studying model sensitivity to misleading and irrelevant instructions.
