# Training Compute-Optimal Large Language Models

**Authors:** Jordan Hoffmann\*, Sebastian Borgeaud\*, Arthur Mensch\*, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, Laurent Sifre\*
**Affiliation:** DeepMind

\*Equal contributions

## Publication Status

- **arXiv preprint:** March 2022, arXiv:2203.15556
- **Peer-reviewed:** Yes
- **Conference:** 36th Conference on Neural Information Processing Systems (NeurIPS 2022), New Orleans, LA, USA, November 28 -- December 9, 2022
- **Status:** Published conference paper

## Preferred Citation

Cite the NeurIPS 2022 version:

> Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., de Las Casas, D., Hendricks, L. A., Welbl, J., Clark, A., Hennigan, T., Noland, E., Millican, K., van den Driessche, G., Damoc, B., Guy, A., Osindero, S., Simonyan, K., Elsen, E., Rae, J. W., Vinyals, O., & Sifre, L. (2022). Training Compute-Optimal Large Language Models. In Advances in Neural Information Processing Systems 35 (NeurIPS 2022), pp. 30016--30030.

## Links

- arXiv: https://arxiv.org/abs/2203.15556
- Proceedings: https://proceedings.neurips.cc/paper_files/paper/2022/hash/c1e2faff6f588870935f114ebe04a3e5-Abstract-Conference.html
- OpenReview: https://openreview.net/forum?id=iBBcRUlOAPR
- Blog post: https://deepmind.google/blog/an-empirical-analysis-of-compute-optimal-large-language-model-training/
