# FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision

**Authors:** Jay Shah*, Ganesh Bikshandi*, Ying Zhang, Vijay Thakkar, Pradeep Ramani, Tri Dao
**Affiliations:** Jay Shah, Ganesh Bikshandi (Colfax Research); Ying Zhang (Meta); Vijay Thakkar (NVIDIA / Georgia Tech); Pradeep Ramani (NVIDIA); Tri Dao (Princeton University / Together AI)

*Equal contribution.

## Publication Status

- **arXiv preprint:** July 2024, arXiv:2407.08608
- **Peer-reviewed:** Yes
- **Conference/Journal:** The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS 2024), Spotlight paper, Vancouver, Canada, December 10--15, 2024
- **Status:** Published conference paper

## Preferred Citation

Cite the NeurIPS 2024 version:

> Shah, J., Bikshandi, G., Zhang, Y., Thakkar, V., Ramani, P., & Dao, T. (2024). FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision. In Advances in Neural Information Processing Systems 37 (NeurIPS 2024).

## Links

- arXiv: https://arxiv.org/abs/2407.08608
- Proceedings: https://proceedings.neurips.cc/paper_files/paper/2024/hash/7ede97c3e082c6df10a8d6103a2eebd2-Abstract-Conference.html
- OpenReview: https://openreview.net/forum?id=tVConYid20
- Code: https://github.com/Dao-AILab/flash-attention
- Blog: https://tridao.me/blog/2024/flash3/
