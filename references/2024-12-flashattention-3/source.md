# FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision

**Authors:** Jay Shah, Ganesh Bikshandi, Ying Zhang, Vijay Thakkar, Pradeep Ramani, Tri Dao
**Affiliations:** Colfax Research, Meta, NVIDIA, Georgia Tech, Princeton University, Together AI

## Publication Status

- **arXiv preprint:** July 2024, arXiv:2407.08608
- **Peer-reviewed:** Yes
- **Conference/Journal:** Advances in Neural Information Processing Systems 37 (NeurIPS 2024), Spotlight paper
- **Status:** Published conference paper

## Preferred Citation

Cite the NeurIPS 2024 version:

> Shah, J., Bikshandi, G., Zhang, Y., Thakkar, V., Ramani, P., & Dao, T. (2024). FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision. In Advances in Neural Information Processing Systems 37 (NeurIPS 2024).

## Links

- arXiv: https://arxiv.org/abs/2407.08608
- Code: https://github.com/Dao-AILab/flash-attention
- Blog: https://tridao.me/blog/2024/flash3/
- OpenReview: https://openreview.net/forum?id=tVConYid20
