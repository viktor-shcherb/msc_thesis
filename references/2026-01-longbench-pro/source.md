# LongBench Pro: A More Realistic and Comprehensive Bilingual Long-Context Evaluation Benchmark

**Authors:** Ziyang Chen, Xing Wu, Junlong Jia, Chaochen Gao, Qi Fu, Debing Zhang, Songlin Hu
**Affiliations:** Ziyang Chen (Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences), Xing Wu (Institute of Information Engineering, Chinese Academy of Sciences), Junlong Jia (School of Artificial Intelligence, Beihang University), Chaochen Gao (Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences), Qi Fu (Xiaohongshu Inc.), Debing Zhang (Xiaohongshu Inc.), Songlin Hu (Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences)

## Publication Status

- **arXiv preprint:** January 2026, arXiv:2601.02872
- **Peer-reviewed:** No
- **Conference/Journal:** Not yet published in a peer-reviewed venue
- **Status:** Preprint

Note: Earlier entries in the same benchmark line were peer-reviewed (LongBench at ACL 2024 and LongBench v2 at ACL 2025), but LongBench Pro is currently an arXiv preprint.

## Preferred Citation

Cite as arXiv preprint:

> Chen, Z., Wu, X., Jia, J., Gao, C., Fu, Q., Zhang, D., & Hu, S. (2026). LongBench Pro: A More Realistic and Comprehensive Bilingual Long-Context Evaluation Benchmark. arXiv:2601.02872.

## Links

- arXiv: https://arxiv.org/abs/2601.02872
- PDF: https://arxiv.org/pdf/2601.02872
- Code: https://github.com/THUDM/LongBench
- Dataset: https://huggingface.co/datasets/caskcsg/LongBench-Pro
- Collection: https://huggingface.co/collections/caskcsg/longbench-pro
