# 100-LongBench: Are *de facto* Long-Context Benchmarks Literally Evaluating Long-Context Ability?

**Authors:** Wang Yang, Hongye Jin, Shaochen Zhong, Song Jiang, Qifan Wang, Vipin Chaudhary, Xiaotian Han
**Affiliations:** Wang Yang, Vipin Chaudhary, Xiaotian Han (Case Western Reserve University); Hongye Jin (Texas A&M University); Shaochen Zhong (Rice University); Song Jiang, Qifan Wang (Meta)

## Publication Status

- **arXiv preprint:** May 2025, arXiv:2505.19293
- **Peer-reviewed:** Yes
- **Conference:** Findings of the Association for Computational Linguistics: ACL 2025, pages 17560--17576, Vienna, Austria, July 27 -- August 1, 2025
- **Status:** Published conference paper (Findings)

## Preferred Citation

Cite the Findings of ACL 2025 version:

> Yang, W., Jin, H., Zhong, S., Jiang, S., Wang, Q., Chaudhary, V., & Han, X. (2025). 100-LongBench: Are *de facto* Long-Context Benchmarks Literally Evaluating Long-Context Ability? In Findings of the Association for Computational Linguistics: ACL 2025, pages 17560--17576.

## Links

- arXiv: https://arxiv.org/abs/2505.19293
- Proceedings: https://aclanthology.org/2025.findings-acl.903/
- DOI: https://doi.org/10.18653/v1/2025.findings-acl.903
- Code: https://github.com/uservan/100-LongBench
