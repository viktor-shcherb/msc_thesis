@misc{2023-06-rope-ntk,
  author = {bloc97},
  title = {{NTK-Aware Scaled RoPE allows LLaMA models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation}},
  year = {2023},
  howpublished = {Reddit post, r/LocalLLaMA},
  url = {https://www.reddit.com/r/LocalLLaMA/comments/14lz7j5/},
  keywords = {informal},
}
