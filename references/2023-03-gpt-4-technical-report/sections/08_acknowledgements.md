# Authorship, Credit Attribution, and Acknowledgements [p. 15-16]

[p. 15] The paper instructs: > "Please cite this work as 'OpenAI (2023)'." [p. 15]

The contributions section lists team roles across many workstreams. Key organizational structure includes:

## Pretraining

[p. 15] **Core contributors:** Christopher Berner (Supercomputing lead), Greg Brockman (Infrastructure lead), Trevor Cai (Throughput lead), David Farhi (Manager of optimization team), Chris Hesse (Infrastructure usability co-lead), Shantanu Jain (Infrastructure usability co-lead), Kyle Kosic (Uptime and stability lead), Jakub Pachocki (Overall lead, optimization lead), Alex Paino (Architecture & data vice lead), Mikhail Pavlov (Software correctness lead), Michael Petrov (Hardware correctness lead), Nick Ryder (Architecture & data lead), Szymon Sidor (Optimization vice lead), Nikolas Tezak (Execution lead), Phil Tillet (Triton lead), Amin Tootoonchian (Model distribution, systems & networking lead), Qiming Yuan (Dataset sourcing and processing lead), Wojciech Zaremba (Manager of dataset team).

Additional teams listed: Compute cluster scaling, Data, Distributed training infrastructure, Hardware correctness, Optimization & architecture, Training run babysitting.

## Long Context

[p. 15] **Core contributors:** Gabriel Goh (Long context co-lead), Lukasz Kaiser (Long context lead), Ben Wang (Attention architecture lead), Clemens Winter (Long context co-lead).

Additional teams: Long context research, Long context kernels (Phil Tillet).

## Vision

[p. 15] **Core contributors:** Trevor Cai (Execution lead), Mark Chen (Vision team co-lead, Deployment lead), Casey Chu (Initial prototype lead), Chris Hesse (Data load balancing & developer tooling lead), Shengli Hu (Vision Safety Evaluations lead), Yongjik Kim (GPU performance lead), Jamie Kiros (Overall vision co-lead, deployment research & evals lead), Daniel Levy (Overall vision co-lead, optimization lead), Christine McLeavey (Vision team lead), David Mely (Data lead), Hyeonwoo Noh (Overall vision co-lead, research lead), Mikhail Pavlov (Scaling engineering lead), Raul Puri (Overall vision co-lead, engineering lead), Amin Tootoonchian (Model distribution, systems & networking lead).

Additional teams: Architecture research, Compute cluster scaling, Distributed training infrastructure, Hardware correctness, Data, Alignment data, Training run babysitting, Deployment & post-training.

## Reinforcement Learning & Alignment

[p. 15] **Core contributors:** Greg Brockman (Core infrastructure author), Arka Dhar (Human data product manager), Liam Fedus (Data flywheel lead), Tarun Gogineni (Model creativity), Rapha Gontijo-Lopes (Synthetic data), Joshua Gross (Data collection engineering co-lead), Johannes Heidecke (Refusals & model safety co-lead), Joost Huizinga (Initial fine-tuning derisking), Teddy Lee (Human data product manager), Jan Leike (Alignment co-lead), Ryan Lowe (Alignment co-lead), Luke Metz (Infrastructure lead, ChatML format lead), Long Ouyang (IF data collection lead), John Schulman (Overall lead), Jerry Tworek (Code lead), Carroll Wainwright (IF data infrastructure lead), Jonathan Ward (Data collection engineering co-lead), Jiayi Weng (RL Infrastructure author), Sarah Yoo (Human data operations manager), Wojciech Zaremba (Human data lead), Chong Zhang (Refusals & model safety co-lead), Shengjia Zhao (Reward model lead), Barret Zoph (Overall training lead).

Additional teams: Dataset contributions, Data infrastructure, ChatML format, Model safety, Flagship training runs, Code capability.

## Evaluation & Analysis

[p. 16] **Core contributors:** Sandhini Agarwal (System card co-lead), Lama Ahmad (Expert red teaming & adversarial testing program lead), Mo Bavarian (Capability prediction co-lead), Tyna Eloundou (Safety evaluations co-lead), Andrew Kondrich (OpenAI Evals open-sourcing co-lead), Gretchen Krueger (System card co-lead), Michael Lampe (Privacy and PII evaluations lead), Pamela Mishkin (Economic impact & overreliance evaluations lead), Benjamin Sokolowsky (Capability prediction co-lead), Jack Rae (Research benchmark execution lead), Chelsea Voss (Eval execution lead), Alvin Wang (OpenAI Evals lead), Kai Xiao (Safety evaluations co-lead), Marvin Zhang (OpenAI Evals open-sourcing co-lead).

Additional teams listed with contributors: OpenAI Evals library, Model-graded evaluation infrastructure, Acceleration forecasting, ChatGPT evaluations, Capability evaluations, Coding evaluations, Real-world use case evaluations, Contamination investigations, Instruction following and API evals, Novel capability discovery, Vision evaluations, Economic impact evaluation, Non-proliferation/international humanitarian law & national security red teaming (Sarah Shoker), Overreliance analysis, Privacy and PII evaluations, Safety and policy evaluations, OpenAI adversarial testers, System card & broader impacts analysis.

---
[p. 16-17 continued]

## Deployment

[p. 16-17] **Core contributors:** Steven Adler (Early stage program management lead), Sandhini Agarwal (Launch safety lead), Derek Chen (Monitoring & response lead), Atty Eleti (GPT-4 API co-lead), Joanne Jang (GPT-4 product co-lead), Angela Jiang (GPT-4 product co-lead), Tomer Kaftan (Inference infrastructure & deployment lead), Rachel Lim (GPT-4 API co-lead), Kim Malfacini (Usage policy lead), Bianca Martin (Release management lead), Evan Morikawa (Engineering lead), Henrique Ponde de Oliveira Pinto (Inference workflow lead), Heather Schmidt (GPT-4 infrastructure management), Maddie Simens (Design lead), Felipe Petroski Such (Inference optimization & reliability lead), Andrea Vallone (Detection & refusals policy lead), Lilian Weng (Applied research lead), Dave Willner (Trust & safety lead), Michael Wu (Inference research lead).

Additional teams: Inference research (Paul Baltescu, Scott Gray, Yuchen He, Arvind Neelakantan, Michael Wu), GPT-4 API & ChatML deployment, GPT-4 web experience, Inference infrastructure, Reliability engineering, Trust & safety engineering (Jeff Belgum, Madelaine Boyd, Vik Goel).

## Trust & Safety Monitoring and Response

[p. 17] Janko Altenschmidt, Anna-Luisa Brakman, Derek Chen, Florencia Leoni Aleman, Molly Lin, Cameron Raymond, CJ Weinmann, Dave Willner, Samuel Wolrich.

## Trust & Safety Policy

[p. 17] Rosie Campbell, Kim Malfacini, Andrea Vallone, Dave Willner.

## Deployment Compute

[p. 17] Peter Hoeschele, Evan Morikawa.

## Product Management

[p. 17] Jeff Harris, Joanne Jang, Angela Jiang.

## Additional Contributions

[p. 17] Sam Altman, Katie Mayer, Bob McGrew, Mira Murati, Ilya Sutskever, Peter Welinder.

Additional teams: Blog post & paper content, Communications, Compute allocation support, Contracting/revenue/pricing & finance support, Launch partners & product operations, Legal, Security & privacy engineering, System administration & on-call support.

## Authorship & Credit Attribution

[p. 17] David Farhi.

## Acknowledgements

[p. 17] The authors acknowledge every OpenAI team member not explicitly mentioned, including those on the executive assistant, finance, go to market, human resources, legal, operations and recruiting teams, stating that everyone at OpenAI has contributed to GPT-4.

Microsoft is thanked for their partnership, especially Microsoft Azure for supporting model training with infrastructure design and management, and the Microsoft Bing team and Microsoft's safety teams for their partnership on safe deployment. [p. 17]

Expert adversarial testers and red teamers who helped test the models at early stages of development and informed risk assessments are acknowledged. Participation in the red teaming process is noted as not being an endorsement of the deployment plans or OpenAI's policies. Named red teamers include: Steven Basart, Sophie Duba, Cesar Ferri, Heather Frase, Gavin Hartnett, Jake J. Hecla, Dan Hendrycks, Jose Hernandez-Orallo, Alice Hunsberger, Rajiv W. Jain, Boru Gollo Jattani, Lauren Kahn, Dan Kaszeta, Sara Kingsley, Noam Kolt, Nathan Labenz, Eric Liddick, Andrew J. Lohn, Andrew MacPherson, Sam Manning, Mantas Mazeika, Anna Mills, Yael Moros, Jimin Mun, Aviv Ovadya, Roya Pakzad, Yifan Peng, Ciel Qi, Alex Rosenblatt, Paul Rottger, Maarten Sap, Wout Schellaert, George Shih, Muhammad Shoker, Melanie Subbiah, Bryan West, Andrew D. White, Anna Katariina Wisakanto, Akhila Yerukola, Lexin Zhou, Xuhui Zhou. [p. 18]

Collaborators at Casetext and Stanford CodeX are thanked for conducting the simulated bar exam: P. Arredondo (Casetext/Stanford CodeX), D. Katz (Stanford CodeX), M. Bommarito (Stanford CodeX), S. Gao (Casetext). [p. 18]

> "GPT-4 was used for help with wording, formatting, and styling throughout this work." [p. 18]

Footnote 11: All author lists sorted alphabetically. [p. 17]
