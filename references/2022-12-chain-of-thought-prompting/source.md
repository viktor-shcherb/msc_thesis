# Chain-of-Thought Prompting Elicits Reasoning in Large Language Models

**Authors:** Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, Denny Zhou
**Affiliation:** Google Research, Brain Team

## Publication Status

- **arXiv preprint:** January 2022, arXiv:2201.11903
- **Peer-reviewed:** Yes
- **Conference:** 36th Conference on Neural Information Processing Systems (NeurIPS 2022), New Orleans, Louisiana, November 28 -- December 9, 2022
- **Status:** Published conference paper

## Preferred Citation

Cite the NeurIPS 2022 version:

> Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E. H., Le, Q. V., & Zhou, D. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. In Advances in Neural Information Processing Systems, 35:24824--24837.

## Links

- arXiv: https://arxiv.org/abs/2201.11903
- NeurIPS Proceedings: https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html
- OpenReview: https://openreview.net/forum?id=_VjQlMeSB_J
- Blog post: https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/
