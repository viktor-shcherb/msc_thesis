# FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness

**Authors:** Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, Christopher Ré
**Affiliations:** Stanford University, University at Buffalo

## Publication Status

- **arXiv preprint:** May 2022, arXiv:2205.14135
- **Peer-reviewed:** Yes
- **Conference:** Advances in Neural Information Processing Systems 35 (NeurIPS 2022), New Orleans, December 2022
- **Status:** Published conference paper

## Preferred Citation

Cite the NeurIPS 2022 version:

> Dao, T., Fu, D. Y., Ermon, S., Rudra, A., & Ré, C. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness. In Advances in Neural Information Processing Systems 35 (NeurIPS 2022).

## Links

- arXiv: https://arxiv.org/abs/2205.14135
- NeurIPS Proceedings: https://proceedings.neurips.cc/paper_files/paper/2022/hash/67d57c32e20fd0a7a302cb81d36e40d5-Abstract-Conference.html
- Code: https://github.com/Dao-AILab/flash-attention
