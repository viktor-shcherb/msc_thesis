# Appendix I. Revision Model Selection Criteria [p. 26]

[p. 26] As described in Section 6.1, in order to effective use their revision model they need to deploy a criteria for selecting the best answer both within a revision trajectory and between multiple parallel trajectories. They use two approaches: 1) ORM verifier; and 2) majority voting.

[p. 26] For the ORM verifier, they train an ORM on the revision model's outputs according to the procedure in Appendix J. At inference, time they use the verifier to select the best answer. Since they have two axes across which to aggregate (within each revision trajectories and between multiple trajectories), they deploy a hierarchical strategy, first selecting the best answer within each revision trajectory and then aggregating these selected answers across trajectories. To select the best answer within each trajectory, they perform best-of-N weighted aggregation and then choose the highest scoring solution with the maximum best-of-N weighted answer. Then, to select the final answer across all revision chains, they perform another round of best-of-N weighted selection using the best answer from each revision chain. The answer after this second round of best-of-N weighted represents their final answer prediction.

[p. 26] For majority voting they found hierarchical aggregation to create problems when the length of the trajectory or the number of trajectories was too small. The problem being that without enough samples, majority voting is unable to effectively select the best option. Therefore, for majority voting, they simply take all answers, across all trajectories, at once and take their majority as the final-answer. They found this to produce much smoother scaling behavior than the hierarchical approach.
