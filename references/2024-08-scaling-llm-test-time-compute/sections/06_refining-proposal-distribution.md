# 6. Refining the Proposal Distribution [p. 10-11]

[p. 10] So far, the paper studied the test-time compute scaling properties of search against verifiers. Now the authors turn to studying the scaling properties of modifying the proposal distribution (Section 2). Concretely, they enable the model to revise its own answers iteratively, allowing the model to dynamically improve its own distribution at test time. Simply prompting existing LLMs to correct their own mistakes tends to be largely ineffective for obtaining performance improvements on reasoning problems [15]. Therefore, the authors build on the recipe prescribed by Qu et al. [28], incorporate modifications for their setting, and finetune language models to iteratively revise their own answers. They first describe how they train and use models that refine their own proposal distribution by sequentially conditioning on their own previous attempts at the question. They then analyze the inference-time scaling properties of revision models. [p. 10]

**Figure 5** (p. 11): *"Parallel sampling (e.g., Best-of-N) verses sequential revisions. Left: Parallel sampling generates N answers independently in parallel, whereas sequential revisions generates each one in sequence conditioned on previous attempts. Right: In both the sequential and parallel cases, we can use the verifier to determine the best-of-N answers (e.g. by applying best-of-N weighted). We can also allocate some of our budget to parallel and some to sequential, effectively enabling a combination of the two sampling strategies. In this case, we use the verifier to first select the best answer within each sequential chain and then select the best answer accross chains."*

The figure has two parts. Left: Two diagrams showing "Parallel Sampling" (a question goes to an LM that produces N independent answers in parallel, e.g., "A: So 7/4 yap/dap...", "A: We have 4 dap...", "A: If 7/4 yaps/dap...") and "Sequential Revisions" (a question goes to an LM that produces a sequence of answers each conditioned on the previous ones: "A: We...", "A: So...", "A: If 7/4..."). Right: Three inference configurations: (1) "Parallel Best-of-N" where the LM proposes answers independently in parallel and the verifier selects the best; (2) "Sequential Revisions" where the verifier selects the best answer from a single sequential chain; (3) "Combining Sequential / Parallel" where the verifier first selects the best answer within each sequential chain and then selects the best answer across chains.

## 6.1. Setup: Training and Using Revision Models

[p. 11] The finetuning procedure for revision models is similar to [28], though the authors introduce some crucial differences. For finetuning, trajectories consisting of a sequence of incorrect answers followed by a correct answer are needed, on which SFT can then be run. Ideally, the correct answer should be *correlated* with the incorrect answers provided in context, so as to effectively teach the model to *implicitly* identify mistakes in examples provided in-context, followed by correcting those mistakes by making edits as opposed to ignoring the in-context examples altogether, and trying again from scratch. [p. 11]

**Generating revision data.** The on-policy approach of Qu et al. [28] for obtaining several multi-turn rollouts was shown to be effective, but it was not entirely feasible in the authors' infrastructure due to compute costs associated with running multi-turn rollouts. Therefore, they sampled **64 responses in parallel** at a higher temperature and post-hoc constructed multi-turn rollouts from these independent samples. Specifically, following the recipe of [1], each correct answer is paired up with a sequence of incorrect answers from this set as context to construct multi-turn finetuning data. Up to **four incorrect answers** in context are included, where the specific number of solutions in context is sampled randomly from a uniform distribution over categories 0 to 4. A **character edit distance metric** is used to prioritize selecting incorrect answers which are correlated with the final correct answer (see Appendix H). The authors note that token edit distance is not a perfect measure of correlation, but they found this heuristic to be sufficient to correlate incorrect in-context answers with correct target answers to facilitate training a meaningful revision model, as opposed to randomly pairing incorrect and correct responses with uncorrelated responses. [p. 11]

**Using revisions at inference-time.** Given a finetuned revision model, a sequence of revisions can be sampled from the model at test-time. While the revision model is only trained with up to four previous answers in-context, longer chains can be sampled by truncating the context to the most recent four revised responses. In Figure 6 (left), as longer chains are sampled from the revision model, the model's pass@1 at each step gradually improves, demonstrating that the model is able to effectively learn from mistakes made by previous answers in context. [p. 11]

---
[p. 12-14 continued]

**Figure 6** (p. 12): *"Left: Our revision model's pass@1 at each revision step. Pass@1 gradually improves after each revision step, even improving beyond the 4 revision steps that it was trained for. We estimate pass@1 at each step by by averaging over the performance of 4 revision trajectories of length 64 for each question in the test-set. Right: Sequential vs parallel sampling from the revision model. Comparing performance when generating N initial answers in parallel from our revision model, verses generating N revisions sequentially, with the model. When using both the verifier and majority voting to select the answer, we see that generating answers sequentially with the revision model narrowly outperforms generating them in parallel."*

Left panel: A scatter plot with x-axis "Number of Generations" (0 to 60) and y-axis "MATH Test Accuracy (%)" (17 to 26). Individual data points show pass@1 at each revision step. The trend is upward: starting around 18% at step 0 and gradually improving, reaching approximately 24-25% by step 60, even beyond the 4 revision steps the model was trained for. Right panel: A line plot with x-axis "Number of Generations" (2^0 to 2^6) and y-axis "MATH Test Accuracy (%)" (approximately 20 to 40). Four lines are shown: Sequential Best-of-N Weighted, Parallel Best-of-N Weighted, Sequential Majority, Parallel Majority. Sequential variants narrowly outperform their parallel counterparts across all generation budgets. Best-of-N Weighted outperforms Majority for both sequential and parallel.

[p. 12] There is a distribution shift at inference time: the model was trained on only sequences with incorrect answers in context, but at test-time the model may sample correct answers that are included in the context. In this case, it may incidentally turn the correct answer into an incorrect answer in the next revision step. The authors find that indeed, similar to Qu et al. [28], around **38% of correct answers get converted back to incorrect ones** with the revision model using a naive approach. Therefore, they employ a mechanism based on sequential majority voting or verifier-based selection to select the most correct answer from the sequence of revisions made by the model (see Figure 5) to produce the best answer. [p. 12]

**Comparisons.** To test the efficacy of modifying the proposal distribution via revisions, the authors set up an even comparison between the performance of sampling N revisions in sequence and sampling N attempts at a question in parallel. In Figure 6 (right), with both the verifier-based and majority-based selection mechanisms, sampling solutions in sequence outperforms sampling them in parallel. [p. 12]

## 6.2. Analysis Results: Test-Time Scaling with Revisions

[p. 12] The authors previously observed that proposing answers sequentially outperforms proposing them in parallel. However, sequential and parallel sampling may have different properties. Sampling answers in parallel may act more as a global search process, providing coverage over many totally different approaches for solving a problem (e.g., different candidates might utilize different high-level approaches altogether). Sequential sampling, on the other hand, may work more as a local refinement process, revising responses that are already somewhat on the right track. Due to these complementary benefits, the authors suggest striking a balance between these two extremes by allocating some of the inference-time budget to parallel sampling (e.g., sqrt(N)) and the rest to sequential revisions (e.g., sqrt(N)). They show the existence of a compute-optimal ratio between sequential and parallel sampling, and examine their relative pros and cons based on difficulty of a given prompt. [p. 12]

**Trading off sequential and parallel test-time compute.** To understand how to optimally allocate sequential and parallel compute, the authors perform a sweep over a number of different ratios. In Figure 7 (left), at a given generation budget, **there exists an ideal sequential to parallel ratio that achieves the maximum accuracy**. In Figure 7 (right), the ideal ratio of sequential to parallel varies depending on a given question's difficulty. In particular, easy questions benefit more from sequential revisions, whereas on difficult questions it is optimal to strike a balance between sequential and parallel computation. This finding supports the hypothesis that sequential revisions (i.e., varying the proposal distribution) and parallel sampling (i.e., search with verifiers) are two complementary axes for scaling up test-time compute, which may be more effective on a per-prompt basis. Examples of model generations are included in Appendix L. Additional results are shown in Appendix B. [p. 12-13]

**Figure 7** (p. 13): *"Left: Varying the ratio of the generation budget allocated sequential revisions to verses parallel samples. Each line represents a fixed generation budget as the ratio is changed. We use the verifier for answer selection. We see that while increased sequential revisions tends to outperform more parallel compute, at higher generation budgets there is an ideal ratio that strikes a balance between the two extremes. Right: Varying the sequential to parallel ratio for a generation budget of 128 across difficulty bins. Using verifier-based selection, we see that the easier questions attain the best performance with full sequential compute. On the harder questions, there is an ideal ratio of sequential to parallel test-time compute."*

Left panel: A line plot with x-axis "Sequential/Parallel Ratio" (2^-7 to 2^7) and y-axis "MATH Test Accuracy (%)" (15 to 45). Multiple lines are shown, each corresponding to a different total generation budget (color-coded by "Number of Generations" ranging from ~10^1 to ~10^2). At higher generation budgets, there is a clear peak at intermediate ratios rather than at the extremes, indicating an optimal balance. At lower budgets, more sequential compute tends to dominate. Right panel: A grouped bar chart with x-axis "Test Questions Binned by Increasing Difficulty Level" (1 to 5) and y-axis "MATH Test Accuracy (%)" (0 to 100). Bars are grouped by difficulty bin, with colors corresponding to different sequential-to-parallel ratios (from 10^-4 to 10^2 on a secondary y-axis "Sequential to Parallel Ratio"). On easy questions (bins 1-2), fully sequential compute achieves the highest accuracy. On harder questions (bins 3-5), an intermediate ratio performs best.

**Compute-optimal revisions.** Given that the efficacy of sequential and parallel sampling depends on question difficulty, the ideal ratio of sequential to parallel compute can be selected per difficulty bin. In Figure 8, results are plotted using this compute-optimal scaling strategy when employing both oracle and predicted notions of difficulty. In both cases, the authors are able to substantially improve test-time compute scaling by improving the proposal distribution via revisions. In particular, at higher generation budgets, parallel sampling seems to plateau, whereas compute-optimal scaling demonstrates continued improvements. For both oracle and predicted difficulty bins, **compute-optimal scaling can outperform best-of-N using up to 4x less test-time compute** (e.g., 64 samples versus 256). These results demonstrate the potential for improved test-time compute scaling by adjusting the proposal distribution on a per-prompt basis. [p. 13]

**Figure 8** (p. 13): *"Comparing compute-optimal test-time compute allocation against the parallel compute baseline with our revision model. By optimally scaling test-time compute according to question difficulty, we find that we can outperform best-of-N using up to 4x less test-time compute (e.g. 64 samples verses 256). 'Compute-optimal oracle' refers to using the oracle difficulty bins derived from the ground truth correctness information, and 'compute optimal predicted' refers to using the PRM's predictions to produce model-predicted difficulty bins."*

The figure is a line plot titled "Compute Optimal Revisions" with x-axis "Generation Budget" (2^1 to 2^7) and y-axis "MATH Test Accuracy (%)" (approximately 20 to 45). Five lines are shown: Majority, Best-of-N Weighted, Compute Optimal Oracle, Compute Optimal Predicted, Parallel. The two compute-optimal curves (oracle and predicted) rise more steeply than the parallel baseline and best-of-N weighted, with compute-optimal oracle slightly above compute-optimal predicted. At a generation budget of 64, the compute-optimal curves roughly match or exceed the parallel baseline at 256, demonstrating the 4x compute savings claim.

**Takeaways for compute-optimal scaling by refining the proposal distribution with revisions** (boxed text, p. 14):
> "We find that there exists a tradeoff between sequential (e.g. revisions) and parallel (e.g. standard best-of-N) test-time computation, and the ideal ratio of sequential to parallel test-time compute depends critically on both the compute budget and the specific question at hand. Specifically, easier questions benefit from purely sequential test-time compute, whereas harder questions often perform best with some ideal ratio of sequential to parallel compute. Moreover, by optimally selecting the best setting for a given question difficulty and test-time compute budget, we can outperform the parallel best-of-N baseline using up to 4x less test-time compute." [p. 14]
