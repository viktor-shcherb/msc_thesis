# References

This file collects bibliographic entries cited in the section notes. Only references that actually appear in the extracted notes are included.

---

## A

**Aerni et al. (2024)**
Michael Aerni, Jie Zhang, and Florian Tramer. Evaluations of machine learning privacy defenses are misleading. In *ACM SIGSAC Conference on Computer and Communications Security*, pp. 1271--1284, 2024. URL https://doi.org/10.1145/3658644.3690194.
- Cited in 16_appendix-h-additional-pretraining-data.md (worst-case memorization canaries).

**Ainslie et al. (2023)**
Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebron, and Sumit Sanghai. Gqa: Training generalized multi-query transformer models from multi-head checkpoints, 2023. URL https://arxiv.org/abs/2305.13245.
- Cited in 02a_model-architecture.md for grouped-query attention (GQA).

**Ali et al. (2024)**
Mehdi Ali, Michael Fromm, Klaudia Thellmann, Jan Ebert, Alexander Arno Weber, Richard Rutmann, Charvi Jain, Max Lubbering, Daniel Steinigen, Johannes Leveling, et al. Teuken-7b-base & teuken-7b-instruct: Towards european llms. *arXiv preprint arXiv:2410.03730*, 2024.
- Cited in 05c_post-training-evaluation.md as a baseline model (Teuken-7B-instruct-v0.6).

**Allal et al. (2025)**
Loubna Ben Allal, Anton Lozhkov, Elie Bakouch, Gabriel Martin Blazquez, Guilherme Penedo, Lewis Tunstall, Andres Marafioti, Hynek Kydlicek, Agustin Piqueres Lajar√≠n, Vaibhav Srivastav, Joshua Lochner, Caleb Fahlgren, Xuan-Son Nguyen, Clementine Fourrier, Ben Burtenshaw, Hugo Larcher, Haojun Zhao, Cyril Zakka, Mathieu Morlon, Colin Raffel, Leandro von Werra, and Thomas Wolf. Smollm2: When smol goes big -- data-centric training of a small language model, 2025. URL https://arxiv.org/abs/2502.02737.
- Cited in 01_introduction.md, 03b_source-datasets.md, 03c_pretraining-curriculum.md, 04b_decontamination.md, 05b_pretraining-evaluation.md as SmolLM2/SmoLM2.

**Amini et al. (2019)**
Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi. MathQA: Towards interpretable math word solving with operation-based formalisms. In *Proceedings of NAACL*, pp. 2357--2367, 2019.
- Cited in 05c_post-training-evaluation.md as MathQA benchmark.

**Anwar et al. (2024)**
Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, et al. Foundational challenges in assuring alignment and safety of large language models. *Transactions on Machine Learning Research*, 2024.
- Cited in 05f_security-safety.md (general safety reference), 16_appendix-h-additional-pretraining-data.md (persistence of poisoned behaviors through post-training).

**Arnett et al. (2024)**
Catherine Arnett, Eliot Jones, Ivan P. Yamshchikov, and Pierre-Luc Langlais. Toxicity of the commons: Curating open-source pre-training data, 2024. URL https://arxiv.org/abs/2410.22587.
- Cited in 03a_data-compliance.md for PleIAs toxicity annotations.

**Association Entscheidsuche (2025)**
Association Entscheidsuche. Entscheidsuche.ch: Open legal data platform. https://entscheidsuche.ch/docs, 2025. Accessed: 2025-08-31.
- Cited in 16_appendix-h-additional-pretraining-data.md (Swiss legal decision documents source).

**Austin et al. (2021)**
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language models. *arXiv preprint arXiv:2108.07732*, 2021.
- Cited in 05c_post-training-evaluation.md as MBPP benchmark.

## B

**Ba et al. (2016)**
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. Layer normalization, 2016. URL https://arxiv.org/abs/1607.06450.
- Cited in 02a_model-architecture.md for LayerNorm.

**Bai et al. (2022a)**
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, et al. Training a helpful and harmless assistant with reinforcement learning from human feedback. *CoRR*, abs/2204.05862, 2022a.
- Cited in 05f_security-safety.md for helpfulness vs. safety trade-off.

**Bai et al. (2022b)**
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, et al. Constitutional AI: harmlessness from AI feedback. *CoRR*, abs/2212.08073, 2022b.
- Cited in 04h_alignment-controversial-topics.md for Constitutional AI approach.

**Bai et al. (2023)**
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, et al. Qwen technical report. *ArXiv*, abs/2309.16609, 2023.
- Cited in 01_introduction.md.

**Bai et al. (2025)**
Yifan Bai, Yiping Bao, Guanduo Chen, Jiahao Chen, Ningxin Chen, Ruijue Chen, Yanru Chen, Yuankun Chen, Yutian Chen, et al. Kimi K2: Open agentic intelligence. *arXiv preprint arXiv:2507.20534*, 2025.
- Cited in 02c_optimizer-training.md for WSD schedule validation.

**Bakouch et al. (2025)**
Elie Bakouch, Loubna Ben Allal, Anton Lozhkov, Nouamane Tazi, et al. SmoILM3: smol, multilingual, long-context reasoner. https://huggingface.co/blog/smollm3, 2025.
- Cited in 02a_model-architecture.md, 05b_pretraining-evaluation.md as SmolLM3 and for cross-document attention.

**Bari et al. (2024)**
M Saiful Bari, Yazeed Alnumay, Norah A Alzahrani, Nouf M Alotaibi, et al. Allam: Large language models for arabic and english. *arXiv preprint arXiv:2407.15390*, 2024.
- Cited in 05c_post-training-evaluation.md as ALLaM baseline.

**Bisk et al. (2020)**
Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, and Yejin Choi. Piqa: Reasoning about physical commonsense in natural language. In *Thirty-Fourth AAAI Conference on Artificial Intelligence*, 2020.
- Cited in 05b_pretraining-evaluation.md as PIQA benchmark.

**Black et al. (2022)**
Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, et al. Gpt-neox-20b: An open-source autoregressive language model. *ArXiv*, abs/2204.06745, 2022.
- Cited in 01_introduction.md for open model ecosystem.

**Blake et al. (2025)**
Charlie Blake, Constantin Eichenberg, Josef Dean, Lukas Balles, Luke Yuri Prince, Bjorn Deiseroth, Andres Felipe Cruz-Salinas, Carlo Luschi, Samuel Weinbach, and Douglas Orr. u-$\mu$p: The unit-scaled maximal update parametrization. In *The Thirteenth International Conference on Learning Representations*, 2025.
- Cited in 02f_final-run-retrospective.md for outlier activation prevention.

**Blakeney et al. (2024)**
Cody Blakeney, Mansheej Paul, Brett W. Larsen, Sean Owen, and Jonathan Frankle. Does your data spark joy? performance gains from domain upsampling at the end of training, 2024.
- Cited in 03c_pretraining-curriculum.md for cooldown experiments methodology.

**Bostrom & Durrett (2020)**
Kaj Bostrom and Greg Durrett. Byte pair encoding is suboptimal for language model pretraining. In *Findings of EMNLP 2020*, pp. 4617--4624, 2020.
- Cited in 05e_verbatim-memorization.md for tokenizer inconsistency.

**Boether et al. (2025)**
Maximilian Boether, Xiaozhe Yao, Tolga Kerimoglu, Dan Graur, Viktor Gsteiger, and Ana Klimovic. Mixtera: A data plane for foundation model training. *arXiv Preprint*, 2025.
- Cited in 01_introduction.md for data mixtures research.

## C

**Calvo Figueras et al. (2025)**
Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria De Dios Flores, and Rodrigo Agerri. Truth knows no language: Evaluating truthfulness beyond english. 2025.
- Cited in 05c_post-training-evaluation.md for TruthfulQA multilingual.

**Carlini et al. (2019)**
Nicholas Carlini, Chang Liu, Ulfar Erlingsson, Jernej Kos, and Dawn Song. The secret sharer: evaluating and testing unintended memorization in neural networks. In *Proceedings of the 28th USENIX Conference on Security Symposium*, SEC'19, pp. 267--284, 2019.
- Cited in 03b_source-datasets.md for canary-based memorization studies, 16_appendix-h-additional-pretraining-data.md (canary types for verbatim memorization study).

**Chai et al. (2024)**
Yekun Chai, Yewei Fang, Qiwei Peng, and Xuhong Li. Tokenization falling short: On subword robustness in large language models. In *Findings of EMNLP 2024*, pp. 1582--1599, 2024.
- Cited in 05e_verbatim-memorization.md for tokenizer inconsistency.

**Chang et al. (2023)**
Kent Chang, Mackenzie Cramer, Sandeep Soni, and David Bamman. Speak, memory: An archaeology of books known to ChatGPT/GPT-4. In *Proceedings of EMNLP 2023*, pp. 7312--7327, 2023.
- Cited in 02c_optimizer-training.md for copyright risks of verbatim regurgitation.

**Chen et al. (2021)**
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, et al. Evaluating large language models trained on code. *arXiv preprint arXiv:2107.03374*, 2021.
- Cited in 05c_post-training-evaluation.md for HumanEval benchmark.

**Chiu et al. (2025)**
Yu Ying Chiu, Liwei Jiang, Bill Yuchen Lin, Chan Young Park, et al. CulturalBench: A robust, diverse and challenging benchmark for measuring LMs' cultural knowledge through human-AI red-teaming. In *Proceedings of the 63rd Annual Meeting of the ACL (Volume 1: Long Papers)*, pp. 25663--25701, 2025.
- Cited in 04b_decontamination.md, 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md for CulturalBench.

**Chowdhery et al. (2022)**
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, et al. Palm: Scaling language modeling with pathways, 2022. URL https://arxiv.org/abs/2204.02311.
- Cited in 02a_model-architecture.md for no biases.

**Clark et al. (2018)**
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. Think you have solved question answering? try arc, the ai2 reasoning challenge. *ArXiv*, abs/1803.05457, 2018.
- Cited in 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md for ARC benchmark.

**Cobbe et al. (2021)**
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, et al. Training verifiers to solve math word problems. *arXiv preprint arXiv:2110.14168*, 2021.
- Cited in 05c_post-training-evaluation.md for GSM8K benchmark.

**Community (2025)**
Marin Community. Marin 8b instruct. https://huggingface.co/marin-community/marin-8b-instruct, 2025.
- Cited in 05c_post-training-evaluation.md as marin-8b-instruct baseline.

**Conneau et al. (2018)**
Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel R. Bowman, Holger Schwenk, and Veselin Stoyanov. Xnli: Evaluating cross-lingual sentence representations. In *Proceedings of EMNLP 2018*. Association for Computational Linguistics, 2018.
- Cited in 05b_pretraining-evaluation.md for XNLI benchmark.

**Cruz & Madonna (2024)**
Felipe A. Cruz and Alberto Madonna. Containers-first user environments on hpe cray ex. In *Proceedings of the Cray User Group Conference (CUG 2024)*, 2024.
- Cited in 06_infrastructure-scaling-efficiency.md for container engine on Alps.

**Cui et al. (2024)**
Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Bingxiang He, Wei Zhu, Yuan Ni, Guotong Xie, Ruobing Xie, Yankai Lin, Zhiyuan Liu, and Maosong Sun. Ultrafeedback: boosting language models with scaled ai feedback. In *Proceedings of the 41st International Conference on Machine Learning*, ICML'24, 2024.
- Cited in 04d_alignment-data.md for UltraFeedback pipeline.

## D

**Dehghani et al. (2023)**
Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr Padlewski, Jonathan Heek, Justin Gilmer, Andreas Peter Steiner, Mathilde Caron, Robert Geirhos, Ibrahim Alabdulmohsin, et al. Scaling vision transformers to 22 billion parameters. In *International conference on machine learning*, pp. 7480--7512. PMLR, 2023.
- Cited in 02a_model-architecture.md for QK-Norm.

**Deng et al. (2024)**
Yue Deng, Wenxuan Zhang, Sinno Jialin Pan, and Lidong Bing. Multilingual jailbreak challenges in large language models. In *The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024*. OpenReview.net, 2024. URL https://openreview.net/forum?id=vESNKdEMGp.
- Cited in 05f_security-safety.md.

**Deutsch et al. (2025)**
Daniel Deutsch, Eleftheria Briakou, Isaac Rayburn Caswell, Mara Finkelstein, Rebecca Galor, Juraj Juraska, Geza Kovacs, Alison Lui, Ricardo Rei, Jason Riesa, Shruti Rijhwani, Parker Riley, Elizabeth Salesky, Firas Trabelsi, Stephanie Winkler, Biao Zhang, and Markus Freitag. WMT24++: Expanding the language coverage of WMT24 to 55 languages & dialects. In *Findings of the Association for Computational Linguistics: ACL 2025*, pp. 12257--12284, Vienna, Austria, July 2025. Association for Computational Linguistics. ISBN 979-8-89176-256-5. doi: 10.18653/v1/2025.findings-acl.634. URL https://aclanthology.org/2025.findings-acl.634/.
- Cited in 05d_low-resource-translation.md.

**DeepSeek-AI et al. (2025)**
DeepSeek-AI, Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025. URL https://arxiv.org/abs/2501.12948.
- Cited in 07_conclusion.md for RLVR pipeline future direction.

**Dong et al. (2024)**
Xin Dong, Yonggan Fu, Shizhe Diao, Wonmin Byeon, Zijia Chen, Ameya Sunil Mahabaleshwarkar, Shih-Yang Liu, Matthijs Van Keirsbilck, Min-Hung Chen, Yoshi Suhara, Yingyan Lin, Jan Kautz, and Pavlo Molchanov. Hymba: A hybrid-head architecture for small language models, 2024. URL https://arxiv.org/abs/2411.13676.
- Cited in 02a_model-architecture.md.

**Dremov et al. (2025)**
Aleksandr Dremov, Alexander Hagele, Atli Kosson, and Martin Jaggi. Training dynamics of the cooldown stage in warmup-stable-decay learning rate scheduler. *Transactions on Machine Learning Research*, 2025. ISSN 2835-8856. URL https://openreview.net/forum?id=ZnSYEcZod3.
- Cited in 01_introduction.md, 02c_optimizer-training.md.

**Dua et al. (2019)**
Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs. In *Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)*, pp. 2368--2378, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1246. URL https://aclanthology.org/N19-1246/.
- Cited in 05c_post-training-evaluation.md.

**Dubey et al. (2024)**
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models. *arXiv e-prints*, 2024.
- Cited in 05c_post-training-evaluation.md as reference for Llama3.1-8B, Llama3.1-8B-Instruct, Llama3.3-70B, Llama3.3-70B-Instruct in Table 16.

**Dussolle et al. (2025)**
Antoine Dussolle, A. Cardena, Shota Sato, and Peter Devine. M-IFEval: Multilingual instruction-following evaluation. In Luis Chiruzzo, Alan Ritter, and Lu Wang (eds.), *Findings of the Association for Computational Linguistics: NAACL 2025*, pp. 6161--6176, Albuquerque, New Mexico, April 2025. Association for Computational Linguistics. ISBN 979-8-89176-195-7. doi: 10.18653/v1/2025.findings-naacl.344. URL https://aclanthology.org/2025.findings-naacl.344/.
- Cited in 05c_post-training-evaluation.md.

## F

**Fan et al. (2025)**
Dongyang Fan, Vinko Sabolcec, Matin Ansaripour, Ayush Kumar Tarun, Martin Jaggi, Antoine Bosselut, and Imanol Schlag. Can performant llms be ethical? quantifying the impact of web crawling opt-outs, 2025. URL https://arxiv.org/abs/2504.06219.
- Cited in 01_introduction.md, 03a_data-compliance.md.

**Fedorov et al. (2024)**
Igor Fedorov, Kate Plawiak, Lemeng Wu, Tarek Elgamal, Naveen Suda, Eric Smith, Hongyuan Zhan, Jianfeng Chi, Yuriy Hulovatyy, Kimish Patel, Zechun Liu, Changsheng Zhao, Yangyang Shi, Tijmen Blankevoort, Mahesh Pasupuleti, Bilge Soran, Zacharie Delpierre Coudert, Rachad Alao, Raghuraman Krishnamoorthi, and Vikas Chandra. Llama guard 3-1b-int4: Compact and efficient safeguard for human-ai conversations. *CoRR*, abs/2411.17713, 2024. doi: 10.48550/ARXIV.2411.17713. URL https://doi.org/10.48550/arXiv.2411.17713.
- Cited in 05f_security-safety.md.

**Feng et al. (2020)**
Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. CodeBERT: A pre-trained model for programming and natural languages. In Trevor Cohn, Yulan He, and Yang Liu (eds.), *Findings of the Association for Computational Linguistics: EMNLP 2020*, pp. 1536--1547, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.139. URL https://aclanthology.org/2020.findings-emnlp.139/.
- Cited in 03b_source-datasets.md.

**Foroutan et al. (2025a)**
Negar Foroutan, Clara Meister, Debjit Paul, Joel Niklaus, Sina Ahmadi, Antoine Bosselut, and Rico Sennrich. Parity-aware byte-pair encoding: Improving cross-lingual fairness in tokenization. In *arXiv*, 2025a. URL https://arxiv.org/abs/2508.04796.
- Cited in 01_introduction.md, 02b_tokenizer.md, 17_appendix-i-tokenizer-selection.md.

**Foroutan et al. (2025b)**
Negar Foroutan, Jakhongir Saydaliev, Ye Eun Kim, and Antoine Bosselut. Conlid: Supervised contrastive learning for low-resource language identification. *ArXiv*, abs/2506.15304, 2025b. URL https://api.semanticscholar.org/CorpusID:279447974.
- Cited in 01_introduction.md.

**Foroutan et al. (2025c)**
Negar Foroutan, Paul Teiletche, Ayush Kumar Tarun, and Antoine Bosselut. Revisiting multilingual data mixtures in language model pretraining. *ArXiv*, 2025c. URL https://arxiv.org/abs/2510.25947.
- Cited in 01_introduction.md.

**Freeman et al. (2024)**
Joshua Freeman, Chloe Rippe, Edoardo Debenedetti, and Maksym Andriushchenko. Exploring memorization and copyright violation in frontier LLMs: A study of the new york times v. openAI 2023 lawsuit. In *Neurips Safe Generative AI Workshop 2024*, 2024. URL https://openreview.net/forum?id=C66DB19At8.
- Cited in 05e_verbatim-memorization.md.

## G

**Gao et al. (2024)**
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le Noac'h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou. The language model evaluation harness, 07 2024. URL https://zenodo.org/records/12608602.
- Cited in 05b_pretraining-evaluation.md.

**Ge et al. (2025)**
Tao Ge, Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, and Dong Yu. Scaling synthetic data creation with 1,000,000,000 personas, 2025. URL https://arxiv.org/abs/2406.20094.
- Cited in 04d_alignment-data.md.

**Gehman et al. (2020)**
Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. Realtoxicityprompts: Evaluating neural toxic degeneration in language models. In Trevor Cohn, Yulan He, and Yang Liu (eds.), *Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020*, volume EMNLP 2020 of *Findings of ACL*, pp. 3356--3369. Association for Computational Linguistics, 2020. doi: 10.18653/V1/2020.FINDINGS-EMNLP.301. URL https://doi.org/10.18653/v1/2020.findings-emnlp.301.
- Cited in 05f_security-safety.md.

**Goldstein et al. (2023)**
Josh A. Goldstein, Girish Sastry, Micah Musser, Renee DiResta, Matthew Gentzel, and Katerina Sedova. Generative language models and automated influence operations: Emerging threats and potential mitigations. *ArXiv*, abs/2301.04246, 2023. URL https://api.semanticscholar.org/CorpusID:255595557.
- Cited in 05f_security-safety.md.

**Gonzalez-Agirre et al. (2025)**
Aitor Gonzalez-Agirre, Marc Pamies, Joan Llop, Irene Baucells, Severino Da Dalt, Daniel Tamayo, Jose Javier Saiz, Ferran Espuna, Jaume Prats, Javier Aula-Blasco, et al. Salamandra technical report. *arXiv preprint arXiv:2502.08489*, 2025.
- Cited in 05c_post-training-evaluation.md.

**Grattafiori et al. (2024)**
Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, Amy Yang, Angela Fan, et al. The llama 3 herd of models, 2024. URL https://arxiv.org/abs/2407.21783.
- Cited in 01_introduction.md, 02a_model-architecture.md, 02d_ablations.md, 03a_data-compliance.md, 03c_pretraining-curriculum.md, 04a_post-training-overview.md.

**Groeneveld et al. (2024)**
Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, et al. Olmo: Accelerating the science of language models. *arXiv preprint arXiv:2402.00838*, 2024.
- Cited in 01_introduction.md.

## H

**Hagele et al. (2024)**
Alexander Hagele, Elie Bakouch, Atli Kosson, Loubna Ben Allal, Leandro Von Werra, and Martin Jaggi. Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations. *Advances in Neural Information Processing Systems*, 2024. URL http://arxiv.org/abs/2405.18392.
- Cited in 01_introduction.md, 02c_optimizer-training.md.

**Hans et al. (2024)**
Abhimanyu Hans, Yuxin Wen, Neel Jain, John Kirchenbauer, Hamid Kazemi, Prajwal Singhania, Siddharth Singh, Gowthami Somepalli, Jonas Geiping, Abhinav Bhatele, and Tom Goldstein. Be like a goldfish, don't memorize! mitigating memorization in generative llms, 2024. URL https://arxiv.org/abs/2406.10209.
- Cited in 01_introduction.md, 02c_optimizer-training.md.

**Hartvigsen et al. (2022)**
Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar. Toxigen: A large-scale machine-generated dataset for implicit and adversarial hate speech detection. In *Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics*, 2022.
- Cited in 05f_security-safety.md.

**He et al. (2024)**
Bobby He, Lorenzo Noci, Daniele Paliotta, Imanol Schlag, and Thomas Hofmann. Understanding and minimising outlier features in transformer training. In *The Thirty-eighth Annual Conference on Neural Information Processing Systems*, 2024. URL https://openreview.net/forum?id=npJQ6qS4bg.
- Cited in 01_introduction.md, 02f_final-run-retrospective.md.

**Hendrycks et al. (2021a)**
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. *Proceedings of the International Conference on Learning Representations (ICLR)*, 2021a.
- Cited in 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md.

**Hendrycks et al. (2021b)**
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. *NeurIPS*, 2021b.
- Cited in 05c_post-training-evaluation.md.

**Henry et al. (2020)**
Alex Henry, Prudhvi Raj Dachapally, Shubham Pawar, and Yuxuan Chen. Query-key normalization for transformers, 2020. URL https://arxiv.org/abs/2010.04245.
- Cited in 02a_model-architecture.md.

**Hernandez-Cano et al. (2025)**
Alejandro Hernandez-Cano, Dhia Garbaya, Imanol Schlag, and Martin Jaggi. Towards Fully FP8 GEMM LLM Training at Scale. *arXiv preprint arXiv:2505.20524*, 2025.
- Cited in 01_introduction.md, 02f_final-run-retrospective.md.

**Hsieh et al. (2024)**
Cheng-Ping Hsieh, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, Yang Zhang, and Boris Ginsburg. Ruler: What's the real context size of your long-context language models?, 2024. URL https://arxiv.org/abs/2404.06654.
- Cited in 05b_pretraining-evaluation.md (long context evaluation).

**Hu et al. (2024)**
Shengding Hu, Yuge Tu, Xu Han, Chaoqun He, Ganqu Cui, Xiang Long, Zhi Zheng, Yewei Fang, Yuxiang Huang, Weilin Zhao, Xinrong Zhang, Zheng Leng Thai, Kaihuo Zhang, Chongyi Wang, Yuan Yao, Chenyang Zhao, Jie Zhou, Jie Cai, Zhongwu Zhai, Ning Ding, Chao Jia, Guoyang Zeng, Dahai Li, Zhiyuan Liu, and Maosong Sun. Minicpm: Unveiling the potential of small language models with scalable training strategies, 2024. URL https://arxiv.org/abs/2404.06395.
- Cited in 02c_optimizer-training.md.

**Huang & Schlag (2025)**
Allen Hao Huang and Imanol Schlag. Deriving activation functions using integration, 2025. URL https://arxiv.org/abs/2411.13010.
- Cited in 01_introduction.md, 02a_model-architecture.md.

**Huang et al. (2022)**
Jie Huang, Hanyin Shao, and Kevin Chen-Chuan Chang. Are large pre-trained language models leaking your personal information? In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (eds.), *Findings of the Association for Computational Linguistics: EMNLP 2022*, pp. 2038--2047, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. URL https://aclanthology.org/2022.findings-emnlp.148/.
- Cited in 02c_optimizer-training.md.

**Hubinger et al. (2024)**
Evan Hubinger, Carson Denison, Jesse Mu, Mike Lambert, Meg Tong, Monte MacDiarmid, Tamera Lanham, Daniel M Ziegler, Tim Maxwell, Newton Cheng, et al. Sleeper agents: Training deceptive llms that persist through safety training. *arXiv preprint arXiv:2401.05566*, 2024.
- Cited in 16_appendix-h-additional-pretraining-data.md (persistence of poisoned behaviors through post-training).

**HuggingFaceTB (2025)**
HuggingFaceTB. Smollm3-3b. https://huggingface.co/HuggingFaceTB/SmolLM3-3B, 2025. URL https://huggingface.co/HuggingFaceTB/SmolLM3-3B. Accessed: 2025-09-01.
- Cited in 05c_post-training-evaluation.md as reference for SmolLM2-1.7B, SmolLM3-3B in Table 16.

## J

**Jain et al. (2024)**
Devansh Jain, Priyanshu Kumar, Samuel Gehman, Xuhui Zhou, Thomas Hartvigsen, and Maarten Sap. Polyglotoxicityprompts: Multilingual evaluation of neural toxic degeneration in large language models. *CoRR*, abs/2405.09373, 2024. doi: 10.48550/ARXIV.2405.09373. URL https://doi.org/10.48550/arXiv.2405.09373.
- Cited in 04d_alignment-data.md.

**Jiang et al. (2021)**
Aiqi Jiang, Xiaohan Yang, Yang Liu, and Arkaitz Zubiaga. Swsr: A chinese dataset and lexicon for online sexism detection, 2021. URL https://arxiv.org/abs/2108.03070.
- Cited in 03a_data-compliance.md.

**Jiang et al. (2023)**
Albert Qiaochu Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lelio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothee Lacroix, and William El Sayed. Mistral 7b. *ArXiv*, abs/2310.06825, 2023. URL https://api.semanticscholar.org/CorpusID:263830494.
- Cited in 01_introduction.md.

## K

**Kamath et al. (2025)**
Gemma Team Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, et al. Gemma 3 technical report. *ArXiv*, abs/2503.19786, 2025. URL https://api.semanticscholar.org/CorpusID:277313563.
- Cited in 01_introduction.md (same paper as Team et al. 2025, different citation form).

**Kandpal et al. (2025)**
Nikhil Kandpal, Brian Lester, Colin Raffel, Sebastian Majstorovic, Stella Biderman, Baber Abbasi, Luca Soldaini, Enrico Shippole, A. Feder Cooper, Aviya Skowron, John Kirchenbauer, Shayne Longpre, Lintang Sutawika, Alon Albalak, Zhenlin Xu, Guilherme Penedo, Loubna Ben Allal, Elie Bakouch, John David Pressman, Honglu Fan, Dashiell Stander, Guangyu Song, Aaron Gokaslan, Tom Goldstein, Brian R. Bartoldson, Bhavya Kailkhura, and Tyler Murray. The common pile v0.1: An 8tb dataset of public domain and openly licensed text, 2025. URL https://arxiv.org/abs/2506.05209.
- Cited in 03b_source-datasets.md.

**Karamolegkou et al. (2023)**
Antonia Karamolegkou, Jiaang Li, Li Zhou, and Anders Sogaard. Copyright violations and large language models. In Houda Bouamor, Juan Pino, and Kalika Bali (eds.), *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing*, pp. 7403--7412, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.458. URL https://aclanthology.org/2023.emnlp-main.458/.
- Cited in 02c_optimizer-training.md.

**Kettunen (2014)**
Kimmo Kettunen. Can type-token ratio be used to show morphological complexity of languages? *Journal of Quantitative Linguistics*, 21(3):223--245, 2014.
- Cited in 05e_verbatim-memorization.md.

**Kingma & Ba (2014)**
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. *CoRR*, abs/1412.6980, 2014. URL https://api.semanticscholar.org/CorpusID:6628106.
- Cited in 02c_optimizer-training.md.

**Kirk et al. (2025)**
Hannah Rose Kirk, Alexander Whitefield, Paul Rottger, Andrew Bean, Katerina Margatina, Juan Ciro, Rafael Mosquera, Max Bartolo, Adina Williams, He He, Bertie Vidgen, and Scott A. Hale. The prism alignment dataset: what participatory, representative and individualised human feedback reveals about the subjective and multicultural alignment of large language models. In *Proceedings of the 38th International Conference on Neural Information Processing Systems*, NIPS '24, Red Hook, NY, USA, 2025. Curran Associates Inc. ISBN 9783331314385.
- Cited in 04d_alignment-data.md, 04h_alignment-controversial-topics.md, 07_conclusion.md.

**Kirchenbauer et al. (2025)**
John Kirchenbauer, Janny Mongkolsupawan, Yuxin Wen, Tom Goldstein, and Daphne Ippolito. A fictional q&a dataset for studying memorization and knowledge acquisition. *arXiv preprint arXiv:2506.05639*, 2025. URL https://arxiv.org/abs/2506.05639.
- Cited in 16_appendix-h-additional-pretraining-data.md (fictional events dataset for non-verbatim memorization study).

**Kocetkov et al. (2022)**
Denis Kocetkov, Raymond Li, Loubna Ben Allal, Jia Li, Chenghao Mou, Carlos Munoz Ferrandis, Yacine Jernite, Margaret Mitchell, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro von Werra, and Harm de Vries. The stack: 3 tb of permissively licensed source code, 2022. URL https://arxiv.org/abs/2211.15533.
- Cited in 03b_source-datasets.md.

**Kocmi et al. (2024)**
Tom Kocmi, Eleftherios Avramidis, Rachel Bawden, Ondrej Bojar, Anton Dvorkovich, Christian Federmann, Mark Fishel, Markus Freitag, Thamme Gowda, Roman Grundkiewicz, Barry Haddow, Marzena Karpinska, Philipp Koehn, Benjamin Marie, Christof Monz, Kenton Murray, Masaaki Nagata, Martin Popel, Maja Popovic, Mariya Shmatova, Steinthor Steingrimsson, and Vilem Zouhar. Findings of the WMT24 general machine translation shared task: The LLM era is here but MT is not solved yet. In Barry Haddow, Tom Kocmi, Philipp Koehn, and Christof Monz (eds.), *Proceedings of the Ninth Conference on Machine Translation*, pp. 1--46, Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.wmt-1.1. URL https://aclanthology.org/2024.wmt-1.1/.
- Cited in 05d_low-resource-translation.md.

**Koehn (2005)**
Philipp Koehn. Europarl: A parallel corpus for statistical machine translation. In *Proceedings of Machine Translation Summit X: Papers*, pp. 79--86, Phuket, Thailand, September 13-15 2005. URL https://aclanthology.org/2005.mtsummit-papers.11.
- Cited in 03b_source-datasets.md.

**Kokel et al. (2025)**
Harsha Kokel, Michael Katz, Kavitha Srinivas, and Shirin Sohrabi. Acpbench: Reasoning about action, change, and planning. In *AAAI*. AAAI Press, 2025.
- Cited in 05c_post-training-evaluation.md.

**Kucharavy et al. (2023)**
Andrei Kucharavy, Zachary Schillaci, Loic Marechal, Maxime Wursch, Ljiljana Dolamic, Remi Sabonnadiere, Dimitri Percia David, Alain Mermoud, and Vincent Lenders. Fundamentals of generative large language models and perspectives in cyber-defense. *CoRR*, abs/2303.12132, 2023. doi: 10.48550/ARXIV.2303.12132. URL https://doi.org/10.48550/arXiv.2303.12132.
- Cited in 05f_security-safety.md.

## L

**Lai et al. (2023)**
Viet Lai, Chien Nguyen, Nghia Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan Rossi, and Thien Nguyen. Okapi: Instruction-tuned large language models in multiple languages with reinforcement learning from human feedback. In Yansong Feng and Els Lefever (eds.), *Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations*, pp. 318--327, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-demo.28. URL https://aclanthology.org/2023.emnlp-demo.28/.
- Cited in 05c_post-training-evaluation.md.

**Lambert et al. (2025)**
Nathan Lambert, Jacob Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze Brahman, Lester James V. Miranda, Alisa Liu, Nouha Dziri, Shane Lyu, Yuling Gu, Saumya Malik, Victoria Graf, Jena D. Hwang, Jiangjiang Yang, Ronan Le Bras, Oyvind Tafjord, Chris Wilhelm, Luca Soldaini, Noah A. Smith, Yizhong Wang, Pradeep Dasigi, and Hannaneh Hajishirzi. Tulu 3: Pushing frontiers in open language model post-training, 2025. URL https://arxiv.org/abs/2411.15124.
- Cited in 01_introduction.md, 04a_post-training-overview.md, 04b_decontamination.md, 04c_sft-data.md.

**Li et al. (2023)**
Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, Joao Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Munoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. Starcoder: may the source be with you!, 2023. URL https://arxiv.org/abs/2305.06161.
- Cited in 03b_source-datasets.md.

**Li et al. (2025)**
Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Gadre, Hritik Bansal, Etash Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas Muennighoff, Reinhard Heckel, Jean Mercat, Mayee Chen, Suchin Gururangan, Mitchell Wortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Abbas, Cheng-Yu Hsieh, Dhruba Ghosh, Josh Gardner, Maciej Kilian, Hanlin Zhang, Rulin Shao, Sarah Pratt, Sunny Sanyal, Gabriel Ilharco, Giannis Daras, Kalyani Marathe, Aaron Gokaslan, Jieyu Zhang, Khyathi Chandu, Thao Nguyen, Igor Vasiljevic, Sham Kakade, Shuran Song, Sujay Sanghavi, Fartash Faghri, Sewoong Oh, Luke Zettlemoyer, Kyle Lo, Alaaeldin El-Nouby, Hadi Pouransari, Alexander Toshev, Stephanie Wang, Dirk Groeneveld, Luca Soldaini, Pang Wei Koh, Jenia Jitsev, Thomas Kollar, Alexandros G. Dimakis, Yair Carmon, Achal Dave, Ludwig Schmidt, and Vaishaal Shankar. Datacomp-lm: In search of the next generation of training sets for language models, 2025. URL https://arxiv.org/abs/2406.11794.
- Cited in 03b_source-datasets.md.

**Licht et al. (2025)**
Hauke Licht, Rupak Sarkar, Patrick Y. Wu, Pranav Goel, Niklas Stoehr, Elliott Ash, and Alexander Hoyle. Measuring scalar constructs in social science with LLMs. In *Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing*. Association for Computational Linguistics, November 2025.
- Cited in 04h_alignment-controversial-topics.md.

**Lin (2004)**
Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In *Text Summarization Branches Out*, pp. 74--81, Barcelona, Spain, July 2004. Association for Computational Linguistics. URL https://aclanthology.org/W04-1013/.
- Cited in 05e_verbatim-memorization.md.

**Lin et al. (2021)**
Stephanie Lin, Jacob Hilton, and Owain Evans. Truthfulqa: Measuring how models mimic human falsehoods. *CoRR*, abs/2109.07958, 2021. URL https://arxiv.org/abs/2109.07958.
- Cited in 05c_post-training-evaluation.md.

**Liu et al. (2020)**
Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. *arXiv preprint arXiv:2007.08124*, 2020.
- Cited in 05c_post-training-evaluation.md.

**Liu et al. (2023)**
Zhengzhong Liu, Aurick Qiao, Willie Neiswanger, Hongyi Wang, Bowen Tan, Tianhua Tao, Junbo Li, Yuqi Wang, Suqi Sun, Omkar Pangarkar, Richard Fan, Yi Gu, Victor Miller, Yonghao Zhuang, Guowei He, Haonan Li, Fajri Koto, Liping Tang, Nikhil Ranjan, Zhiqiang Shen, Xuguang Ren, Roberto Iriondo, Cun Mu, Zhiting Hu, Mark Schulze, Preslav Nakov, Timothy Baldwin, and Eric P. Xing. Llm360: Towards fully transparent open-source llms. *ArXiv*, abs/2312.06550, 2023. URL https://api.semanticscholar.org/CorpusID:266162750.
- Cited in 01_introduction.md.

**Liu et al. (2024)**
Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. *arXiv preprint arXiv:2412.19437*, 2024.
- Cited in 02c_optimizer-training.md.

**Liu et al. (2025a)**
Chris Yuhao Liu, Liang Zeng, Yuzhen Xiao, Jujie He, Jiacai Liu, Chaojie Wang, Rui Yan, Wei Shen, Fuxiang Zhang, Jiacheng Xu, Yang Liu, and Yahui Zhou. Skywork-reward-v2: Scaling preference data curation via human-ai synergy. *arXiv preprint arXiv:2507.01352*, 2025a.
- Cited in 04g_alignment-standard-topics.md.

**Liu et al. (2025b)**
Zhengzhong Liu, Bowen Tan, Hongyi Wang, Willie Neiswanger, Tianhua Tao, Haonan Li, Fajri Koto, Yuqi Wang, Suqi Sun, Omkar Pangarkar, Richard Fan, Yi Gu, Victor Miller, Liqun Ma, Liping Tang, Nikhil Ranjan, Yonghao Zhuang, Guowei He, Renxi Wang, Ming Deng, Robin Algayres, Yuanzhi Li, Zhiqiang Shen, Preslav Nakov, and Eric Xing. Llm360 k2: Building a 65b 360-open-source large language model from scratch. *ArXiv*, abs/2501.07124, 2025b. URL https://api.semanticscholar.org/CorpusID:275471059.
- Cited in 01_introduction.md.

**Liu et al. (2025c)**
Zhengzhong Liu, Bowen Tan, Hongyi Wang, Willie Neiswanger, Tianhua Tao, Haonan Li, Fajri Koto, Yuqi Wang, Suqi Sun, Omkar Pangarkar, et al. Llm360 k2: Building a 65b 360-open-source large language model from scratch. *arXiv preprint arXiv:2501.07124*, 2025c.
- Cited in 05c_post-training-evaluation.md.

**Longpre et al. (2023)**
Shayne Longpre, Robert Mahari, Anthony Chen, Naana Obeng-Marnu, Damien Sileo, William Brannon, Niklas Muennighoff, Nathan Khazam, Jad Kabbara, Kartik Perisetla, et al. The data provenance initiative: A large scale audit of dataset licensing & attribution in ai. *arXiv preprint arXiv:2310.16787*, 2023.
- Cited in 03b_source-datasets.md.

**Longpre et al. (2024)**
Shayne Longpre, Robert Mahari, Ariel Lee, Campbell Lund, Hamidah Oderinwale, William Brannon, Nayan Saxena, Naana Obeng-Marnu, Tobin South, Cole Hunter, et al. Consent in crisis: The rapid decline of the ai data commons. *Advances in Neural Information Processing Systems*, 37:108042--108087, 2024.
- Cited in 03a_data-compliance.md.

**Loshchilov & Hutter (2017)**
Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization in adam. *ArXiv*, abs/1711.05101, 2017. URL https://api.semanticscholar.org/CorpusID:3312944.
- Cited in 02c_optimizer-training.md.

**Luukkonen et al. (2024)**
Risto Luukkonen, Jonathan Burdge, Elaine Zosa, Aarne Talman, Ville Komulainen, Vaino Hatanpaa, Peter Sarlin, and Sampo Pyysalo. Poro 34b and the blessing of multilinguality, 2024.
- Cited in 05b_pretraining-evaluation.md.

## M

**Majumdar & Vogelsang (2024)**
Subhabrata Majumdar and Terry Vogelsang. *Towards Safe LLMs Integration*, pp. 243--247. Springer Nature Switzerland, Cham, 2024. ISBN 978-3-031-54827-7. doi: 10.1007/978-3-031-54827-7_27. URL https://doi.org/10.1007/978-3-031-54827-7_27.
- Cited in 05f_security-safety.md.

**MacFarlane (2012)**
John MacFarlane. pandoc user's guide, 2012.
- Cited in 16_appendix-h-additional-pretraining-data.md (HTML to Markdown conversion for Swiss legal documents).

**Meister (2025)**
Clara Meister. [unclear: full title and venue -- not visible in pages 91-96; cited in Appendix I as the source for the Gini coefficient adapted to quantify tokenizer fairness across languages]. 2025.
- Cited in 17_appendix-i-tokenizer-selection.md (Gini coefficient for tokenizer fairness).

**Marinas et al. (2025)**
Ines Altemir Marinas, Anastasiia Kucherenko, and Andrei Kucharavy. Going over fine web with a fine-tooth comb: Technical report of indexing fine web for problematic content search and retrieval, 2025. URL https://arxiv.org/abs/2508.21788.
- Cited in 01_introduction.md.

**Martinasso et al. (2025)**
Maxime Martinasso, Mark Klein, and Thomas C. Schulthess. Alps, a versatile research infrastructure, 2025. URL https://arxiv.org/abs/2507.02404.
- Cited in 06_infrastructure-scaling-efficiency.md.

**Martins et al. (2024)**
PH Martins, P Fernandes, J Alves, NM Guerreiro, R Rei, DM Alves, J Pombal, A Farajian, M Faysse, M Klimaszewski, et al. Eurollm: Multilingual language models for europe (arxiv: 2409.16235). arxiv, 2024.
- Cited in 05c_post-training-evaluation.md (Table 16 baseline entries: EuroLLM-1.7B, EuroLLM-9B, EuroLLM-22B-Instruct-Preview, EuroLLM-9B-Instruct).

**Martins et al. (2025)**
Pedro Henrique Martins, Joao Alves, Patrick Fernandes, Nuno M. Guerreiro, Ricardo Rei, Amin Farajian, Mateusz Klimaszewski, Duarte M. Alves, Jose Pombal, Manuel Faysse, Pierre Colombo, Francois Yvon, Barry Haddow, Jose G. C. de Souza, Alexandra Birch, and Andre F. T. Martins. Eurollm-9b: Technical report, 2025.
- Cited in 01_introduction.md, 03b_source-datasets.md, 03c_pretraining-curriculum.md, 04a_post-training-overview.md, 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md.

**Matrenok et al. (2025)**
Simon Matrenok, Skander Moalla, and Caglar Gulcehre. Quantile reward policy optimization: Alignment with pointwise regression and exact partition functions, 2025. URL https://arxiv.org/abs/2507.08068.
- Cited in 01_introduction.md, 04a_post-training-overview.md, 04f_preference-alignment.md.

**Mazeika et al. (2024)**
Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo Li, David Forsyth, and Dan Hendrycks. Harmbench: A standardized evaluation framework for automated red teaming and robust refusal. *URL https://arxiv.org/abs/2402.04249*, 2024.
- Cited in 05f_security-safety.md.

**McCandlish et al. (2018)**
Sam McCandlish, Jared Kaplan, Dario Amodei, and OpenAI Dota Team. An empirical model of large-batch training. *arXiv preprint arXiv:1812.06162*, 2018.
- Cited in 02c_optimizer-training.md.

**Merrill et al. (2025)**
William Merrill, Shane Arora, Dirk Groeneveld, and Hannaneh Hajishirzi. Critical batch size revisited: A simple empirical approach to large-batch language model training. *arXiv preprint arXiv:2505.23971*, 2025.
- Cited in 02c_optimizer-training.md.

**Mesnard et al. (2024)**
Gemma Team Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, et al. Gemma: Open models based on gemini research and technology. *ArXiv*, abs/2403.08295, 2024. URL https://api.semanticscholar.org/CorpusID:268379206.
- Cited in 01_introduction.md.

**Messmer et al. (2025)**
Bettina Messmer, Vinko Sabolcec, and Martin Jaggi. Enhancing multilingual llm pretraining with model-based data selection, 2025. URL https://arxiv.org/abs/2502.10361.
- Cited in 01_introduction.md, 03b_source-datasets.md.

**Moalla (2025)**
Skander Moalla. Python Machine Learning Research Template, 2025. URL https://github.com/CLAIRE-Labo/python-ml-research-template.
- Cited in 04a_post-training-overview.md.

**Muennighoff et al. (2025)**
Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Candes, and Tatsunori Hashimoto. s1: Simple test-time scaling, 2025. URL https://arxiv.org/abs/2501.19393.
- Cited in 04c_sft-data.md.

**Myung et al. (2025)**
Junho Myung, Nayeon Lee, Yi Zhou, Jiho Jin, Rifki Afina Putri, Dimosthenis Antypas, Hsuvas Borkakoty, Eunsu Kim, Carla Perez-Almendros, Abinew Ali Ayele, Victor Gutierrez-Basulto, Yazmin Ibanez-Garcia, Hwaran Lee, Shamsuddeen Hassan Muhammad, Kiwoong Park, Anar Sabuhi Rzayev, Nina White, Seid Muhie Yimam, Mohammad Taher Pilehvar, Nedjma Ousidhoum, Jose Camacho-Collados, and Alice Oh. Blend: A benchmark for llms on everyday knowledge in diverse cultures and languages, 2025. URL https://arxiv.org/abs/2406.09948.
- Cited in 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md.

**Meta AI (2025)**
Meta AI. Introducing llama-4: Advancing multimodal intelligence. https://ai.meta.com/blog/llama-4-multimodal-intelligence/, 2025. Accessed: 2025-09-01.
- Cited in 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md as Llama4-Scout-16x17B.

## N

**NLP (2024)**
Sapienza NLP. Minerva-7b-instruct-v1.0. https://huggingface.co/sapienzanlp/Minerva-7B-instruct-v1.0, 2024. URL https://huggingface.co/sapienzanlp/Minerva-7B-instruct-v1.0. Accessed: 2025-09-01.
- Cited in 05c_post-training-evaluation.md as Minerva-7B-instruct-v1.0 baseline.

**Ning et al. (2025)**
Zhiyuan Ning, Tianle Gu, Jiaxin Song, Shixin Hong, Lingyu Li, Huacan Liu, Jie Li, Yixu Wang, Meng Lingyu, Yan Teng, et al. Linguasafe: A comprehensive multilingual safety benchmark for large language models. *arXiv preprint arXiv:2508.12733*, 2025.
- Cited in 05f_security-safety.md.

**nll (2024)**
nll (2024). FLORES+ development set.
- Cited in 02b_tokenizer.md.

## O

**OLMo et al. (2025)**
Team OLMo, Pete Walsh, Luca Soldaini, Dirk Groeneveld, Kyle Lo, Shane Arora, Akshita Bhagia, Yuling Gu, Shengyi Huang, Matt Jordan, et al. 2 olmo 2 furious. *arXiv preprint arXiv:2501.00656*, 2024.
- Cited in 02d_ablations.md, 04a_post-training-overview.md, 04b_decontamination.md, 04c_sft-data.md, 05b_pretraining-evaluation.md.

**OpenAI (2024)**
OpenAI. Openai o1 system card, Dec 2024. URL https://openai.com/index/openai-o1-system-card/.
- Cited in 07_conclusion.md.

**OpenAI et al. (2025)**
OpenAI, :, Sandhini Agarwal, Lama Ahmad, Jason Ai, Sam Altman, Andy Applebaum, Edwin Arbus, et al. gpt-oss-120b & gpt-oss-20b model card, 2025. URL https://arxiv.org/abs/2508.10925.
- Cited in 02a_model-architecture.md, 05b_pretraining-evaluation.md.

**Ouyang et al. (2022)**
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. *Advances in neural information processing systems*, 35:27730--27744, 2022.
- Cited in 04f_preference-alignment.md.

## P

**Pagliardini et al. (2025)**
Matteo Pagliardini, Pierre Ablin, and David Grangier. The adEMAMix optimizer: Better, faster, older. In *The Thirteenth International Conference on Learning Representations*, 2025. URL https://openreview.net/forum?id=jj7b3p5kLY.
- Cited in 01_introduction.md, 02c_optimizer-training.md, 04e_supervised-finetuning.md, 04f_preference-alignment.md.

**Pal et al. (2024)**
Arka Pal, Deep Karkhanis, Samuel Dooley, Manley Roberts, Siddartha Naidu, and Colin White. Smaug: Fixing failure modes of preference optimisation with dpo-positive, 2024. URL https://arxiv.org/abs/2402.13228.
- Cited in 04f_preference-alignment.md.

**Papineni et al. (2002)**
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Pierre Isabelle, Eugene Charniak, and Dekang Lin (eds.), *Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics*, pp. 311--318, Philadelphia, Pennsylvania, USA, July 2002. Association for Computational Linguistics. doi: 10.3115/1073083.1073135. URL https://aclanthology.org/P02-1040/.
- Cited in 05d_low-resource-translation.md.

**Parrish et al. (2022)**
Alicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, Jana Thompson, Phu Mon Htut, and Samuel Bowman. BBQ: A hand-built bias benchmark for question answering. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (eds.), *Findings of the Association for Computational Linguistics: ACL 2022*, pp. 2086--2105, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.findings-acl.165. URL https://aclanthology.org/2022.findings-acl.165.
- Cited in 05f_security-safety.md.

**Penedo et al. (2024a)**
Guilherme Penedo, Hynek Kydlicek, Loubna Ben allal, Anton Lozhkov, Margaret Mitchell, Colin Raffel, Leandro Von Werra, and Thomas Wolf. The fineweb datasets: Decanting the web for the finest text data at scale, 2024a. URL https://arxiv.org/abs/2406.17557.
- Cited in 03a_data-compliance.md, 03b_source-datasets.md.

**Penedo et al. (2024b)**
Guilherme Penedo, Hynek Kydlicek, Alessandro Cappelli, Mario Sasko, and Thomas Wolf. Datatrove: large scale data processing, 2024b. URL https://github.com/huggingface/datatrove.
- Cited in 03b_source-datasets.md.

**Penedo et al. (2025)**
Guilherme Penedo, Hynek Kydlicek, Vinko Sabolcec, Bettina Messner, Negar Foroutan, Amir Hossein Kargaran, Colin Raffel, Martin Jaggi, Leandro Von Werra, and Thomas Wolf. Fineweb2: One pipeline to scale them all--adapting pre-training data processing to every language. *arXiv preprint arXiv:2506.20920*, 2025.
- Cited in 01_introduction.md, 03a_data-compliance.md, 03b_source-datasets.md, 15_appendix-g-fineweb2-language-distribution.md (FineWeb-2 language distribution).

**Peng et al. (2023)**
Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. Yarn: Efficient context window extension of large language models. *arXiv preprint arXiv:2309.00071*, 2023.
- Cited in 02a_model-architecture.md.

## Q

**Qwen et al. (2024)**
Qwen An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, et al. Qwen2.5 technical report. *ArXiv*, abs/2412.15115, 2024b. (Same paper as Yang et al. 2024b.)
- Cited in 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md.

## R

**Radford et al. (2018)**
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by generative pre-training. 2018.
- Cited in 02a_model-architecture.md.

**Rafailov et al. (2023)**
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. Direct preference optimization: your language model is secretly a reward model. In *Proceedings of the 37th International Conference on Neural Information Processing Systems*, NIPS '23, Red Hook, NY, USA, 2023. Curran Associates Inc.
- Cited in 04f_preference-alignment.md.

**Rafailov et al. (2024)**
Rafael Rafailov, Yaswanth Chittepu, Ryan Park, Harshit Sushil Sikchi, Joey Hejna, Brad Knox, Chelsea Finn, and Scott Niekum. Scaling laws for reward model overoptimization in direct alignment algorithms. *Advances in Neural Information Processing Systems*, 37:126207--126242, 2024.
- Cited in 04f_preference-alignment.md.

**Raffel et al. (2020)**
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. *Journal of machine learning research*, 21(140):1--67, 2020.
- Cited in 02a_model-architecture.md.

**Rando & Tram√®r (2024)**
Javier Rando and Florian Tram√®r. Universal jailbreak backdoors from poisoned human feedback. In *The Twelfth International Conference on Learning Representations*, 2024. URL https://openreview.net/forum?id=GxCGsxiAaK.
- Cited in 16_appendix-h-additional-pretraining-data.md (poisoning attack design inspiration).

**Rein et al. (2024)**
David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R Bowman. Gpqa: A graduate-level google-proof q&a benchmark. In *First Conference on Language Modeling*, 2024.
- Cited in 05c_post-training-evaluation.md.

**Riviere et al. (2024)**
Riviere et al. (2024). Open model progression.
- Cited in 01_introduction.md, 04a_post-training-overview.md.

**Roemmele et al. (2011)**
Melissa Roemmele, Cosmin Adrian Bejan, and Andrew S Gordon. Choice of plausible alternatives: An evaluation of commonsense causal reasoning. In *2011 AAAI Spring Symposium Series*, 2011. URL https://people.ict.usc.edu/~gordon/publications/AAAI-SPRING11A.PDF.
- Cited in 05b_pretraining-evaluation.md.

**Romanou et al. (2025)**
Angelika Romanou, Negar Foroutan, Anna Sotnikova, Zeming Chen, Sree Harsha Nelaturu, Shivalika Singh, Rishabh Maheshwary, Micol Altomare, Mohamed A Haggag, Alfonso Amayuelas, Azril Hafizi Amirudin, Viraat Aryabumi, Danylo Boiko, Michael Chang, Jenny Chim, Gal Cohen, Kumar Dalmia, Abraham Diress, Sharad Duwal, Daniil Dzenhaliou, Daniel Fernando Erazo Florez, Fabian Farestam, Aditya Joseph Marvin Imperial, Shayekh Bin Islam, Perttu Isotalo, Maral Jabbarishiviari, Borje F. Karlsson, Eldar Khalilov, Christopher Klamm, Fajri Koto, Dominik Krzeminski, Gabriel Adriano de Melo, Syrielle Montariol, Yiyang Nan, Joel Niklaus, Jekaterina Novikova, Johan Samir Obando Ceron, Debjit Paul, Esther Ploeger, Jebish Purbey, Swati Rajwal, Selvan Sunitha Ravi, Sara Rydell, Roshan Santhosh, Drishti Sharma, Marjana Prifti Skenduli, Soltani Arshia Moakhar, Bardia Soltani Moakhar, Ran Tamir, Ayush Kumar Tarun, Azmine Toushik Wasi, Thenuka Ovin Weerasinghe, Serhan Yilmaz, Mike Zhang, Imanol Schlag, Marzieh Fadaee, Sara Hooker, and Antoine Bosselut. Include: Evaluating multilingual language understanding with regional knowledge. In *ICLR*, 2025.
- Cited in 01_introduction.md, 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md.

**Rosenthal & Veraldi (2025)**
David Rosenthal and Livio Veraldi. Training AI language models with third-party content and data from a legal perspective. *Jusletter-IT*, March 2025. doi: 10.38023/bec9257a-a6bb-41cf-b2f3-fda8ae3b448d. URL https://www.rosenthal.ch/downloads/Rosenthal-Veraldi_Training_LLM_Swiss_Law_Jusletter_IT.pdf.
- Cited in 03a_data-compliance.md.

**Roettger et al. (2024)**
Paul Rottger, Hannah Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi, and Dirk Hovy. XSTest: A test suite for identifying exaggerated safety behaviours in large language models. In *Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)*, pp. 5377--5400, Mexico City, Mexico, June 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.naacl-long.301.
- Cited in 05f_security-safety.md.

## S

**Sakaguchi et al. (2019)**
Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarial winograd schema challenge at scale. *arXiv preprint arXiv:1907.10641*, 2019.
- Cited in 05b_pretraining-evaluation.md.

**Scao et al. (2022)**
Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagn'e, et al. Bloom: A 176b-parameter open-access multilingual language model. *ArXiv*, abs/2211.05100, 2022. URL https://api.semanticscholar.org/CorpusID:253420279.
- Cited in 01_introduction.md.

**Schaipp et al. (2025)**
Fabian Schaipp, Alexander Hagele, Adrien Taylor, Umut Simsekli, and Francis Bach. The surprising agreement between convex optimization theory and learning-rate scheduling for large model training. *Forty-second International Conference on Machine Learning*, 2025. URL https://arxiv.org/abs/2501.18965.
- Cited in 02c_optimizer-training.md.

**Schuppli et al. (2025)**
Stefano Schuppli, Fawzi Mohamed, Henrique Mendonca, Nina Mujkanovic, Elia Palme, Dino Conciatore, Lukas Drescher, Miguel Gila, Pim Witlox, Joost VandeVondele, Maxime Martinasso, Thomas C. Schulthess, and Torsten Hoefler. Evolving hpc services to enable ml workloads on hpe cray ex, 2025. URL https://arxiv.org/abs/2507.01880.
- Cited in 06_infrastructure-scaling-efficiency.md.

**Schulman et al. (2017)**
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms, 2017. URL https://arxiv.org/abs/1707.06347.
- Cited in 04f_preference-alignment.md.

**Semenov et al. (2025)**
Andrei Semenov, Matteo Pagliardini, and Martin Jaggi. Benchmarking optimizers for large language model pretraining. *arXiv preprint arXiv:2509.01440*, 2025. URL https://arxiv.org/abs/2509.01440.
- Cited in 01_introduction.md, 02c_optimizer-training.md.

**Sennrich et al. (2016)**
Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. In *Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pp. 1715--1725, Berlin, Germany, August 2016. Association for Computational Linguistics. doi: 10.18653/v1/P16-1162.
- Cited in 02b_tokenizer.md.

**Shao et al. (2024)**
Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo. Deepseekmath: Pushing the limits of mathematical reasoning in open language models, 2024. URL https://arxiv.org/abs/2402.03300.
- Cited in 04f_preference-alignment.md.

**Shazeer et al. (2017)**
Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. *arXiv preprint arXiv:1701.06538*, 2017.
- Cited in 02f_final-run-retrospective.md.

**Shi et al. (2022)**
Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, et al. Language models are multilingual chain-of-thought reasoners. *arXiv preprint arXiv:2210.03057*, 2022.
- Cited in 05c_post-training-evaluation.md.

**Shoeybi et al. (2019)**
Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. Megatron-lm: Training multi-billion parameter language models using model parallelism, 2019. URL https://arxiv.org/abs/1909.08053.
- Cited in 02a_model-architecture.md, 03c_pretraining-curriculum.md.

**Singh et al. (2025)**
Shivalika Singh, Angelika Romanou, Clementine Fourrier, David I. Adelani, Jian Gang Ngui, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre, Wei-Yin Ko, Madeline Smith, Antoine Bosselut, Alice Oh, Andre F. T. Martins, Leshem Choshen, Daphne Ippolito, Enzo Ferrante, Marzieh Fadaee, Beyza Ermis, and Sara Hooker. Global mmlu: Understanding and addressing cultural and linguistic biases in multilingual evaluation. In *ACL*, 2025. URL https://arxiv.org/abs/2412.03304.
- Cited in 01_introduction.md, 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md.

**Smith et al. (2018)**
Samuel L Smith, Pieter-Jan Kindermans, Chris Ying, and Quoc V Le. Don't decay the learning rate, increase the batch size. In *International Conference on Learning Representations*, 2018.
- Cited in 02c_optimizer-training.md.

**So et al. (2021)**
David R. So, Wojciech Manke, Hanxiao Liu, Zihang Dai, Noam Shazeer, and Quoc V. Le. Primer: Searching for efficient transformers for language modeling, 2021. URL https://arxiv.org/abs/2109.08668.
- Cited in 02a_model-architecture.md.

**Stammbach et al. (2024)**
Dominik Stammbach, Philine Widmer, Eunjung Cho, Caglar Gulcehre, and Elliott Ash. Aligning large language models with diverse political viewpoints. In *Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing*, pp. 7257--7267, 2024.
- Cited in 04h_alignment-controversial-topics.md, 07_conclusion.md.

**Su et al. (2021)**
Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding, 2021. URL https://arxiv.org/abs/2104.09864.
- Cited in 02a_model-architecture.md.

**Suzgun et al. (2022)**
Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou, , and Jason Wei. Challenging big-bench tasks and whether chain-of-thought can solve them. *arXiv preprint arXiv:2210.09261*, 2022.
- Cited in 05c_post-training-evaluation.md.

## T

**Team (2025)** / **Team et al. (2025)**
Gemma Team Aishwarya Kamath, Johan Ferret, Shreya Pathak, Nino Vieillard, Ramona Merhej, Sarah Perrin, Tatiana Matejovicova, Alexandre Ram'e, Morgane Riviere, Louis Rouillard, Thomas Mesnard, et al. Gemma 3 technical report. *ArXiv*, abs/2503.19786, 2025. URL https://api.semanticscholar.org/CorpusID:277313563.
- Cited in 05c_post-training-evaluation.md, 05f_security-safety.md.

**Touvron et al. (2023a)**
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, Aur'elien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models. *ArXiv*, abs/2302.13971, 2023a. URL https://api.semanticscholar.org/CorpusID:257219404.
- Cited in 01_introduction.md.

**Touvron et al. (2023b)**
Hugo Touvron, Louis Martin, Kevin R. Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, et al. Llama 2: Open foundation and fine-tuned chat models. *ArXiv*, abs/2307.09288, 2023b. URL https://api.semanticscholar.org/CorpusID:259950998.
- Cited in 01_introduction.md.

**The Swiss Parliament (2024)**
The Swiss Parliament. Entscheidsuche.ch: Open legal data platform. https://www.parlament.ch/en/ratsbetrieb/curia-vista, 2024. Accessed: 2024-04-24.
- Cited in 16_appendix-h-additional-pretraining-data.md (Curiavista parliamentary proceedings source).

## U

**Ustun et al. (2024)**
Ahmet Ustun, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel D'souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, and Sara Hooker. Aya model: An instruction finetuned open-access multilingual language model. *arXiv preprint arXiv:2402.07827*, 2024.
- Cited in 01_introduction.md (footnote 2).

## V

**Vamvas et al. (2025)**
Jannis Vamvas, Ignacio Perez Prat, Not Battesta Soliva, Sandra Baltermia-Guetg, Andrina Beeli, Simona Beeli, Madlaina Capeder, Laura Decurtins, Gian Peder Gregori, Flavia Hobi, Gabriela Holderegger, Arina Lazzarini, Viviana Lazzarini, Walter Rosselli, Bettina Vital, Anna Rutkiewicz, and Rico Sennrich. Expanding the WMT24++ benchmark with Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader. 2025. URL https://arxiv.org/abs/2509.03148.
- Cited in 05d_low-resource-translation.md.

**Vaswani et al. (2017)**
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need, 2017. URL https://arxiv.org/abs/1706.03762.
- Cited in 02a_model-architecture.md.

## W

**Wang & Komatsuzaki (2021)**
Ben Wang and Aran Komatsuzaki. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax, May 2021.
- Cited in 01_introduction.md.

**Wang et al. (2024)**
Wenxuan Wang, Zhaopeng Tu, Chang Chen, Youliang Yuan, Jen-tse Huang, Wenxiang Jiao, and Michael Lyu. All languages matter: On the multilingual safety of LLMs. In *Findings of the Association for Computational Linguistics: ACL 2024*, pp. 5865--5877, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.349.
- Cited in 05f_security-safety.md.

**Wang et al. (2025)**
Victor Wang, Michael J. Q. Zhang, and Eunsol Choi. Improving llm-as-a-judge inference with the judgment distribution, 2025. URL https://arxiv.org/abs/2503.03064.
- Cited in 04h_alignment-controversial-topics.md.

**Wei et al. (2022)**
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. *Advances in neural information processing systems*, 35:24824--24837, 2022.
- Cited in 07_conclusion.md for reasoning with adaptive compute.

**Wicks et al. (2024)**
Rachel Wicks, Matt Post, and Philipp Koehn. Recovering document annotations for sentence-level bitext. In *Findings of the Association for Computational Linguistics: ACL 2024*, pp. 9876--9890, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-acl.589.
- Cited in 03b_source-datasets.md.

**Wolf et al. (2020)**
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural language processing, 2020. URL https://github.com/huggingface/transformers.
- Cited in 02a_model-architecture.md.

**Wuhrmann et al. (2025)**
Arthur Wuhrmann, Andrei Kucharavy, and Anastasiia Kucherenko. Low-perplexity LLM-generated sequences and where to find them. In *Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)*, pp. 774--783, Vienna, Austria, July 2025. Association for Computational Linguistics. doi: 10.18653/v1/2025.acl-srw.51.
- Cited in 01_introduction.md.

## X

**Xiao et al. (2024)**
Guangxuan Xiao, Yuandong Tian, Beidi Chen, Song Han, and Mike Lewis. Efficient streaming language models with attention sinks, 2024. URL https://arxiv.org/abs/2309.17453.
- Cited in 02a_model-architecture.md.

**Xiong et al. (2020)**
Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen Xing, Huishuai Zhang, Yanyan Lan, Liwei Wang, and Tie-Yan Liu. On layer normalization in the transformer architecture, 2020. URL https://arxiv.org/abs/2002.04745.
- Cited in 02a_model-architecture.md.

**Xu (2025)**
Yixuan Xu. Quantifying training data retention in large language models: An analysis of pretraining factors and mitigation strategies, aug 2025. URL https://infoscience.epfl.ch/handle/20.500.14299/253615.
- Cited in 01_introduction.md, 02c_optimizer-training.md, 03b_source-datasets.md, 05e_verbatim-memorization.md, 14_appendix-f-goldfish-loss.md.

**Xu et al. (2025)**
Yixuan Xu, Antoni-Joan Solergibert i Llaquet, Antoine Bosselut, and Imanol Schlag. Positional fragility in LLMs: How offset effects reshape our understanding of memorization risks, 2025. URL https://arxiv.org/abs/2505.13171.
- Cited in 01_introduction.md, 02c_optimizer-training.md, 03b_source-datasets.md, 05e_verbatim-memorization.md, 16_appendix-h-additional-pretraining-data.md (memorization research).

## Y

**Yang et al. (2024a)**
An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Ke-Yang Chen, Kexin Yang, Mei Li, Min Xue, Na Pei, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Yang Fan, Yang Yao, Yichang Zhang, Yunyang Wan, Yunfei Chu, Zeyu Cui, Zhenru Zhang, and Zhi-Wei Fan. Qwen2 technical report. *ArXiv*, abs/2407.10671, 2024a. URL https://api.semanticscholar.org/CorpusID:271212307.
- Cited in 01_introduction.md.

**Yang et al. (2024b)**
Qwen An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxin Yang, Jingren Zhou, Junyan Lin, Kai Dang, Keqin Bao, Ke-Pei Yang, Le Yu, Li-Chun Deng, Mei Li, Min Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shi-Qiang Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingwang Wang, Xinyu Zhang, Xinyu Wang, Xinyue Zhang, Xuancheng Ren, Xinyu Zhang, Yang Fan, Yang Su, Yi-Chao Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, and Zihan Qiu. Qwen2.5 technical report. *ArXiv*, abs/2412.15115, 2024b. URL https://api.semanticscholar.org/CorpusID:274859421.
- Cited in 01_introduction.md, 04a_post-training-overview.md.

**Yang et al. (2025a)**
An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxin Yang, Jingren Zhou, Junyan Lin, Kai Dang, Keqin Bao, Ke-Pei Yang, Le Yu, Li-Chun Deng, Mei Li, Min Xue, Mingze Li, Pei Zhang, Peng Wang, Qin Zhu, Rui Men, Ruize Gao, Shi-Qiang Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin, Xingwang Wang, Xinyu Zhang, Xinyu Wang, Xinyue Zhang, Xuancheng Ren, Xinyu Zhang, Yang Fan, Yang Su, Yi-Chao Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng Zhou, and Zihan Qiu. Qwen3 technical report. *ArXiv*, abs/2505.09388, 2025a. URL https://api.semanticscholar.org/CorpusID:278602855.
- Cited in 01_introduction.md, 18_appendix-j-post-training-supplementary.md.

**Yang et al. (2025b)**
An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. *arXiv preprint arXiv:2505.09388*, 2025b.
- Cited in 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md.

**Yong et al. (2023)**
Zheng Xin Yong, Cristina Menghini, and Stephen H. Bach. Low-resource languages jailbreak GPT-4. *CoRR*, abs/2310.02446, 2023. doi: 10.48550/ARXIV.2310.02446. URL https://doi.org/10.48550/arXiv.2310.02446.
- Cited in 05f_security-safety.md.

## Z

**Zellers et al. (2019)**
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. Hellaswag: Can a machine really finish your sentence? In *Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics*, 2019.
- Cited in 05b_pretraining-evaluation.md, 05c_post-training-evaluation.md.

**Zhai et al. (2022)**
Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer. Scaling vision transformers, 2022. URL https://arxiv.org/abs/2106.04560.
- Cited in 02c_optimizer-training.md.

**Zhang & Sennrich (2019)**
Biao Zhang and Rico Sennrich. Root mean square layer normalization, 2019. URL https://arxiv.org/abs/1910.07467.
- Cited in 02a_model-architecture.md.

**Zhang et al. (2022)**
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona T. Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer. Opt: Open pre-trained transformer language models. *ArXiv*, abs/2205.01068, 2022. URL https://api.semanticscholar.org/CorpusID:248496292.
- Cited in 01_introduction.md.

**Zhang et al. (2025)**
Yiming Zhang, Javier Rando, Ivan Evtimov, Jianfeng Chi, Eric Michael Smith, Nicholas Carlini, Florian Tramer, and Daphne Ippolito. Persistent pre-training poisoning of LLMs. In *The Thirteenth International Conference on Learning Representations*, 2025. URL https://openreview.net/forum?id=eiqrnVaeIw.
- Cited in 03b_source-datasets.md, 16_appendix-h-additional-pretraining-data.md (data poisoning research).

**Zhong et al. (2024)**
Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan. AGIEval: A human-centric benchmark for evaluating foundation models. In Kevin Duh, Helena Gomez, and Steven Bethard (eds.), *Findings of the Association for Computational Linguistics: NAACL 2024*, pp. 2299--2314, Mexico City, Mexico, June 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.findings-naacl.149.
- Cited in 05c_post-training-evaluation.md.

**Zhou et al. (2023)**
Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi Luan, Denny Zhou, and Le Hou. Instruction-following evaluation for large language models, 2023. URL https://arxiv.org/abs/2311.07911.
- Cited in 05c_post-training-evaluation.md.

**Zhou et al. (2025a)**
Enyu Zhou, Guodong Zheng, Binghai Wang, Zhiheng Xi, Shihan Dou, Rong Bao, Wei Shen, Limao Xiong, Jessica Fan, Yurong Mou, Rui Zheng, Tao Gui, Qi Zhang, and Xuanjing Huang. RMB: Comprehensively benchmarking reward models in LLM alignment. In *The Thirteenth International Conference on Learning Representations*, 2025a. URL https://openreview.net/forum?id=kmgr1G9TR0.
- Cited in 04g_alignment-standard-topics.md.

**Zhou et al. (2025b)**
Fan Zhou, Zengzhi Wang, Nikhil Ranjan, Zhoujun Cheng, Liping Tang, Guowei He, Zhengzhong Liu, and Eric P. Xing. Megamath: Pushing the limits of open math corpora. *arXiv preprint arXiv:2504.02807*, 2025b. Preprint.
- Cited in 03b_source-datasets.md.

**Zollo et al. (2024)**
Thomas P Zollo, Andrew Wei Tung Siah, Naimeng Ye, Ang Li, and Hongseok Namkoong. Personalllm: Tailoring llms to individual preferences. *arXiv preprint arXiv:2409.20296*, 2024.
- Cited in 04h_alignment-controversial-topics.md.
