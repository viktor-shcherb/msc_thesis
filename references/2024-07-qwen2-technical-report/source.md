# Qwen2 Technical Report

**Authors:** An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xuancheng Ren, Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhifang Guo, Zhihao Fan
**Affiliation:** Alibaba Group

## Publication Status

- **arXiv preprint:** July 2024, arXiv:2407.10671
- **Peer-reviewed:** No
- **Conference/Journal:** None
- **Status:** Preprint

Qwen2 was released as a technical report alongside model weights in sizes ranging from 0.5B to 72B parameters. The models were released under permissive licenses (Apache 2.0 for most sizes, Qianwen License for 72B). The report describes the full Qwen2 model family including dense language models, a Mixture-of-Experts model (Qwen2-57B-A14B), and covers architecture, training data, and evaluation.

## Preferred Citation

> Yang, A., Yang, B., Hui, B., Zheng, B., Yu, B., Zhou, C., ... & Fan, Z. (2024). Qwen2 Technical Report. arXiv:2407.10671.

## Links

- arXiv: https://arxiv.org/abs/2407.10671
- Code: https://github.com/QwenLM/Qwen2
- Models: https://huggingface.co/Qwen
- Blog: https://qwenlm.github.io/blog/qwen2/
