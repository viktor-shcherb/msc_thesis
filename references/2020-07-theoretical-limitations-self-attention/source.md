# Theoretical Limitations of Self-Attention in Neural Sequence Models

**Author:** Michael Hahn
**Affiliation:** Stanford University

## Publication Status

- **arXiv preprint:** June 2019, arXiv:1906.06755
- **Peer-reviewed:** Yes
- **Journal:** Transactions of the Association for Computational Linguistics (TACL), 2020, Volume 8, pp. 156--171
- **Presented at:** ACL 2020 (58th Annual Meeting of the Association for Computational Linguistics), July 5--10, 2020, Online
- **Action Editor:** Yoav Goldberg
- **Status:** Published journal paper

## Preferred Citation

Cite the TACL 2020 version:

> Hahn, M. (2020). Theoretical Limitations of Self-Attention in Neural Sequence Models. Transactions of the Association for Computational Linguistics, 8:156--171.

## Links

- arXiv: https://arxiv.org/abs/1906.06755
- ACL Anthology: https://aclanthology.org/2020.tacl-1.11/
- MIT Press: https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00306/43545
- DOI: https://doi.org/10.1162/tacl_a_00306
