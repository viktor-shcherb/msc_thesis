# Context Length Alone Hurts LLM Performance Despite Perfect Retrieval

**Authors:** Yufeng Du, Minyang Tian, Srikanth Ronanki, Subendhu Rongali, Sravan Babu Bodapati, Aram Galstyan, Azton Wells, Roy Schwartz, Eliu A. Huerta, Hao Peng
**Affiliations:** University of Illinois Urbana-Champaign, Amazon, Hebrew University of Jerusalem, Argonne National Laboratory

## Publication Status

- **arXiv preprint:** October 2025, arXiv:2510.05381
- **Peer-reviewed:** Yes
- **Conference:** EMNLP 2025 Findings (Conference on Empirical Methods in Natural Language Processing), November 5--9, 2025, Suzhou, China
- **Status:** Published (Findings of EMNLP)

Note: "Findings" papers undergo the same peer review as main conference papers but are presented in a separate track. They are considered peer-reviewed publications.

## Preferred Citation

Cite the EMNLP 2025 Findings version:

> Du, Y., Tian, M., Ronanki, S., Rongali, S., Bodapati, S. B., Galstyan, A., Wells, A., Schwartz, R., Huerta, E. A., & Peng, H. (2025). Context Length Alone Hurts LLM Performance Despite Perfect Retrieval. In Findings of the Association for Computational Linguistics: EMNLP 2025.

## Links

- arXiv: https://arxiv.org/abs/2510.05381
- ACL Anthology: https://aclanthology.org/2025.findings-emnlp.1264/
