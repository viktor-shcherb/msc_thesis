Les grands mod\`eles de langage annoncent des fen\^etres de contexte de 128K
tokens ou plus, mais leur longueur de contexte effective---la port\'ee sur
laquelle ils utilisent l'information de mani\`ere fiable---reste souvent bien
en de\c{c}\`a. Les benchmarks comportementaux d\'etectent cet \'ecart sans
pouvoir l'expliquer. Nous d\'eveloppons un cadre m\'ecaniste qui retrace la
d\'egradation en contexte long \`a la g\'eom\'etrie des repr\'esentations de
requ\^ete et de cl\'e au sein des t\^etes d'attention.

Notre m\'ethode capture les vecteurs de requ\^ete et de cl\'e apr\`es
l'application de RoPE et applique trois analyses compl\'ementaires. La
d\'ecomposition en composantes principales r\'ev\`ele que l'encodage
positionnel domine la structure de variance des t\^etes. Un mod\`ele de
rotation planaire isole la direction de d\'erive positionnelle asym\'etrique et
produit une force de biais scalaire par t\^ete. La plasticit\'e
attentionnelle mesure ensuite la cons\'equence fonctionnelle~: la probabilit\'e
qu'une requ\^ete al\'eatoire inverse l'ordre de pr\'ef\'erence entre deux
cl\'es. Nous prouvons que la plasticit\'e d\'ecro\^it avec la position de la
requ\^ete sous une d\'erive positionnelle lin\'eaire, et d\'erivons une forme
ferm\'ee gaussienne qui d\'ecompose cette d\'ecroissance en composantes
positionnelle et s\'emantique.

Nous analysons 13 mod\`eles issus de trois familles (Ministral-3, Qwen-3,
Llama-3.2) et suivons 10 points de contr\^ole d'entra\^inement de SmolLM3-3B
\`a travers le pr\'e-entra\^inement et l'extension de contexte long. La chute
de plasticit\'e---la d\'egradation entre les positions de contexte proches et
lointaines---s\'epare les familles de mod\`eles dans le m\^eme ordre que les
scores LongBench-Pro~: Ministral ($\sim$0.07) surpasse Qwen ($\sim$0.17) qui
surpasse Llama (0.23). La dynamique d'entra\^inement r\'ev\`ele que le
recalibrage des fr\'equences RoPE effondre le biais positionnel mais
n'emp\^eche pas la d\'ecroissance de la plasticit\'e aux positions lointaines,
indiquant que la r\'eduction du biais est n\'ecessaire mais non suffisante pour
un contexte long effectif.
