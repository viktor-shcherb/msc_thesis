\section{Problem Statement}

The gap between claimed and effective context length is well-documented
behaviorally, but the internal mechanisms that produce this gap remain poorly
understood. Existing mechanistic studies have identified individual failure
pathways---positional bias in attention
patterns~\cite{2024-02-lost-in-the-middle}, attention
sinks~\cite{2025-04-attention-sink-emerges}, fragile retrieval
heads~\cite{2025-04-retrieval-head-long-context-factuality}---but no
existing method provides a unified, quantitative framework that connects
internal attention geometry to behavioral long-context performance across
models.

This thesis addresses the question: \emph{can the geometry of query and key
representations inside attention heads predict and explain effective context
length?}
